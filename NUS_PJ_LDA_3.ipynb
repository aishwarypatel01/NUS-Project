{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457
        },
        "id": "Q38V83I6O8rt",
        "outputId": "ef00fd04-596e-4878-88f4-ac8b8ee1068a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas==1.5.3\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m67.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==1.5.3) (1.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.2\n",
            "    Uninstalling pandas-2.0.2:\n",
            "      Successfully uninstalled pandas-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install pandas==1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 877
        },
        "id": "08ZLPLfmPVwO",
        "outputId": "e5e8ee4b-7fd3-4f85-c9aa-4f86ba97bf9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.24.2 (from pyLDAvis)\n",
            "  Downloading numpy-1.25.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m78.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Collecting pandas>=2.0.0 (from pyLDAvis)\n",
            "  Downloading pandas-2.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m111.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
            "Collecting tzdata>=2022.1 (from pandas>=2.0.0->pyLDAvis)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: funcy, tzdata, numpy, pandas, pyLDAvis\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.0.2 which is incompatible.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.25.0 which is incompatible.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.25.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 numpy-1.25.0 pandas-2.0.2 pyLDAvis-3.4.1 tzdata-2023.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "import spacy\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "\n",
        "# libraries for visualization\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "h8dyJwF1PdVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_data= pd.read_csv(\"prepro.csv\")\n",
        "print(review_data.head(2))\n",
        "print(len(review_data))"
      ],
      "metadata": {
        "id": "j510Bk_3PhaK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb38dc06-ccbd-4e6f-dc70-d7c5f9de0426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Review Polarity_score\n",
            "0  Dr. Meadows made me feel comfortable upon our ...       POSITIVE\n",
            "1  Helen is amazing, she helped me open doors tha...       POSITIVE\n",
            "107224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lis = []\n",
        "for ind in review_data.index:\n",
        "  if (review_data['Polarity_score'][ind] == 'NEGATIVE'):\n",
        "    lis.append(review_data['Review'][ind])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoiMGx-IZciK",
        "outputId": "b8229e22-1e24-47b2-9708-0032fc321dff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhC8hculhKlP",
        "outputId": "1ed04749-1c9d-41f5-8262-78f9ba209e30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['I love my therapist. took me a few tries to find her through the app. I am however not as impressed with the tech. the video is choppy and sometimes doesnt let me log in. Also, there arent any discounts available to refer friends, which seems like a good idea. I was not able to help a couple friends who needed it at a lower rate. I received it during a promotion. And lastly, I havent been able to find out how to pause service to save on weeks not utilized. If these issues were addressed, it would really be a superb app that I would definitely refer.',\n",
              " \"Usually therapy is stressful and feels like homework and I feel like I disappoint my therapists. Anita doesn't stress me out. She doesn't make me feel like I owe her anything. She encourages me when im taking steps towards better health, and consoles me when I mess up\",\n",
              " \"She's knowledgeable, empathetic, and doesn't give pat answers.\",\n",
              " 'She gets me me and I am a complicated mess',\n",
              " \"She has mad it easyer for me to talk about thing i don't like talking about.\",\n",
              " \"I felt that Judy was kind 'in person' over video chat, but her kindness did not translate well over text message. Each message I received was short and succinct. I also felt as if she made a judgement on who I was without really knowing me.\",\n",
              " 'Intelligent charismatic disarming',\n",
              " 'She really tries to understand problems and not just offer any solution off the top of her head.',\n",
              " 'She didn’t want to work with me since I had chronic illnesses that may be causing some of my mental and emotional struggles. I get it, but it was hurtful since it took a lot for me to even want to try Better Help. She didn’t even let us get to our first video session.',\n",
              " '10/10 anything else is a misclick',\n",
              " 'Instantly knew what my problems are',\n",
              " 'Iris is exactly what I have been looking for!  She gets straight to the point and gives you tools to work with.  I have had trouble finding a good  counselor up until now, I feel like most of them just sit there and listen and give me nothing.',\n",
              " \"Emmanuel took me on as a client, but then simply didn't have time for me. Extremely disappointing\",\n",
              " 'Monica seems nice, and polite from what I got to know about her. She wasn’t responsive enough and when she was it was days later, so I wouldnt hold high expectations for this . I got nothing out of this service, I specifically asked to be matched with a counselor of color, and had to be rematches at least 6 times. It got to the point I had to just given in to what ever I got. I told some of my story and what my expectations were. And it was a waste. I feel unheard, and like just another number, like no really cared, not even about trying to help me sort some things out. All in all this was a waste. Money down the drain and you know what really helped an app called Youper.',\n",
              " 'Discovering aspects of my life for which I have not considered in determining\\nmy present state of unhappiness.',\n",
              " 'Stephanie is very light with her approach. She’s doesn’t make you feel like you’re talking to a counselor.',\n",
              " 'I have had a single conversation with her. I do not know her well enough to make any assessment.',\n",
              " 'She is very knowledgeable and doesn’t let me get away with my shit. Most therapists don’t know how to talk to me, she does',\n",
              " 'Bomb diggity',\n",
              " 'Haven’t felt this great in a long time.',\n",
              " \"Sessions with Dr. Briley were an oar in the water, constantly directing my thinking in productive rather than counter-productive ways, the very thing that was causing my anxiety in the first place.\\n\\nDr. Briley and BetterHelp were what I needed, exactly when I needed it. In less than two weeks, I went from thinking I was stuck with a mental illness for good to not needing SSRIs, not experience panics attacks, and basically not even feeling anxiety. I wouldn't have believed it 2 weeks ago!\",\n",
              " \"I really don't believe I could have found a better counselor. He always keeps me thinking.\",\n",
              " 'Ms Browning sent me some questionnaires that I’ve not addressed so, my review is incomplete.',\n",
              " \"She tells you things you don't want to hear but need to hear to grow.\",\n",
              " 'I was initially apprehensive about therapy - but after several months with Gabrielle,   I stopped for a month and my family  noticed a negative Change in my behavior again. I’m back and have  a more positive outlook on therapy in general.\\n\\nAlso- I believe I accidentally selected a negative comment in the survey section. It Was a mistake and I don’t want that To have a negative impact.',\n",
              " 'Listens to me when I am not comfortable talking to family and friends about personal mental health problems. I dont want to explode anymore. So talking it out with a third party is a lifesaver.',\n",
              " 'Dear Ann -Marie Caddie Logan- I apologize for nut reaching out to you as I had logged on but never use this email address. I have since received 6 months worth of payments without ever having contact with you. I hope you and/or your company can resolve this.  Given I have never once had contact and by accident I am billed continuously. Obviously that was a mistake. Thank you best regards johan',\n",
              " 'Eileen was fine, there are systemic issues  with Better Help with initially finding a counsellor. Was in a bit of a pickle right at the start and found this annoying and depressing.There seems to be an issue with dealing with people like me in another time zone.',\n",
              " 'She seems to have no real interest in her patients or passion for her work. Ending sessions early, failing to really listen or offer any helpful suggestions, perfunctory chat check ins with no content or compassion. I had high hopes for her but it seems that after a couple of sessions she mentally checked out. Very disappointed',\n",
              " 'Had a lovely first session, and then I received an email telling me that I was not compatible with her, without specific details included. Honestly, bring rejected by your therapist without a specific reason is the last thing you’d want from a therapist.',\n",
              " 'I personally did not connect well with Angela. I found that in our sessions we talked a lot about what happened in my week where I was waiting to talk about more intense issues in my life. She did help me figure out how to transition to another therapist and was very supportive and kind, just not the right therapist for me!',\n",
              " \"I have been procrastinating on beginning therapy as therapy itself is a stress factor for me, so I was very disappointed when I finally made an appointment and then  she didn't show up to our session.\",\n",
              " 'I was going through depression and anxiety for months I was also experiencing mood swings and suicidal thoughts I tried ending my life a few times but I was too scared to do it I’m feeling a lot better but I ain’t completely over the way I feel I have anger issues and get mad easily when I think about certain things from the past',\n",
              " \"She very concerned in how I'm doing and how I feel and my sleep and the problems I'm having\",\n",
              " 'I couldn’t of made these last few months without you',\n",
              " 'I feel like caralee really zeros in on how to help me and what I’m struggling with.',\n",
              " 'Jerry has helped me thru some rough times in my life and I’m scared to lose him. I won’t be able to afford this much longer and scared to what’s gonna happen next',\n",
              " \"Formulaic. Distant. A reason I give up on counseling. Reaffirmation that I'm not understandable.\",\n",
              " 'Texting is not therapy. Very disappointed.',\n",
              " 'I have a life threatening chronic illness and was paired with a therapist that understands medical terminology.',\n",
              " 'I was happy she decided to follow up once, however when I informed her about how my day was going which included thoughts of suicide, our meeting was cancelled immediately,  she gave me no reason as to why she couldn’t help or no recommendations as to who I should seek. This would be my second time changing my counselor.',\n",
              " 'When I first spoke to Tonia, I was broken. I couldn’t even open up. She was there for me and now I barely get triggers.',\n",
              " 'Ms. Daly has been an absolute wonder for my mental health!',\n",
              " 'She was unresponsive and seems to not take this job seriously. I was in urgent need of therapy and on the first day already, she was not responding to my messages.',\n",
              " 'Christopher seems like a well-meaning man, but he is very lacking in responses. I usually only received one reply a day, with a sentence or two at most. After sending him multiple paragraphs of my thoughts/feelings. While I appreciate he wanted to set goals, there were never any specific goals set or made.',\n",
              " 'I was in a really tough hole, I couldn’t see the light at the end of the tunnel.  Robin offered me guidance by listening to me, actually hearing me and offering me input as well as educating me about coping mechanisms.  I already miss her!',\n",
              " \"This service is one of those things that leaves you wondering why it hadn't been invented a few years ago.\",\n",
              " 'Dr. Jones started our  first session late and was pushing to redirect me to another third party site to sign away all my privacy. I told her I wasn’t comfortable doing that and she was very dismissive and told me to find someone else. \\n\\nBe covert cautious about a therapist that immediately wants to direct you to a third party to give up all your patient rights. This is unnecessary and makes me wonder why she was adamant on doing this.',\n",
              " 'The only reason it’s not a 10 is because of money',\n",
              " \"As soon as I opened up she took 48 hours to respond and then threw me to the side and recommended I try another therapist. Didn't even try to schedule a meeting for us to talk or anything. Honestly disheartening to my entire experiance.\",\n",
              " \"I did not enjoy my experience with this counselor. We had a scheduled chat session and while we were chatting the replies were really slow. Sometimes it would take up to 15 minutes in between her responses. It felt like I didn't have her full attention and it felt like a waste of my time. It wasn't clear how the session was supposed to go or how long I had to chat with her. This experience turned me off of wanting to continue using this service. I will be deleting my account.\",\n",
              " 'Ellen has contempt for most patients and phones it in around the others.',\n",
              " \"I've had many therapists in my life, but no one has understood me like Thérèse has.\",\n",
              " 'This woman was absolutely the worst therapist. She is extremely unprofessional, doesn’t listen, and would rather talk about herself instead. She does not genuinely care. Avoid her! Therapist red flags everywhere!!!',\n",
              " 'Dr. Fletcher has been the worst experience with a therapist I have ever had and left me very upset.',\n",
              " 'Honestly talking to Harry is less like talking to a doctor and more talking to a professional friend. To put the experience bluntly from past therapy compared to this, he’s not your stereotypical Hollywood therapist where it’s like talking to a brick wall with a judgemental face. Definitely feels more like talking to a friend. Would recommend him to anyone, especially if they’re on the verge of quitting therapy.',\n",
              " \"I've suffered from depression for 30 years. I have made more progress with her than I  have with anyone in the past. I usually won't talk to a therapist because it hasn't helped in the past, I have only talked to my psychiatrist for many years. I have felt comfortable with Wendy since day one.\",\n",
              " 'Jennifer changed my worldview on how I think about mental health and addiction from the first session.   This is not your father\\'s \"tell me about your mother\" therapy session. Way better!',\n",
              " 'Barely replies to texts.',\n",
              " 'Stephanie has been great and it saddens me that she is going.',\n",
              " 'She was great at first but it’s been almost a week now with no response. I feel like my money is being wasted',\n",
              " 'I have been doing therapy for 15 years and I have never met someone who truly really wants to help me get better',\n",
              " 'I already have recommended this app to friends. I was scared of what could be I couldn’t see how badly I needed a change!',\n",
              " 'Lots of technical difficulties using this app',\n",
              " 'If you are someone who has a hard time opening up to others',\n",
              " 'I had my first session scheduled several days in advance with Dr. Haley. She did not show up for our session which is very disappointing and did not help my emotional state. I would hope that the doctors on here or anywhere would be professional and come to the scheduled appointments.',\n",
              " 'I have never done a session like this before but I can tell that will be able to help me. I have either a councillor that doesn’t understand what I am trying to tell them or uses technics that is really confusing. I haven’t felt that with Dr. Hardin.',\n",
              " \"As for so many others, my personal and work life were both severely impacted by the pandemic. The future was looking rather bleak and, perhaps worse, everyone around me seemed to agree that nothing was going to be getting any better. My Wednesday sessions with Dr. Harrell have been immensely valuable in all of this and I'm really not sure whether I'd have been able to get back on my feet without her support. To the best of my knowledge, she cannot fly or shoot laser beams from her eyeballs but if I did have the option of swapping Dr. Harrell for the Second Coming of Christ, I think I'd politely decline.\",\n",
              " 'I never thought that so many things get buried in oneself that later causes destruction. My counseling sessions made look at what really is the problem and to address it.',\n",
              " \"I've been working with Dr Hassert for a couple weeks now. I have been in other therapeutic situations and have not had the success I have had in my short time with Dr Hassert.\",\n",
              " \"Before starting my sessions with Dr. Helmholdt I was really in pretty rough shape. I had zero energy. I was mentally and  physically very sick. I was extremely depressed, and was suffering from intense anxiety. My schizoaffective disorder was the worst it has been in many years. I wasn't really working anymore. I honestly wasn't taking care of myself anymore. I had no confidence, and I had zero motivation. I really feel like she brought me back to the light. I felt like I was in darkness for so long. I just want her to know how extremely grateful I am for her putting me back on the right path! THANK YOU SO MUCH!!!\",\n",
              " 'She understands narcissists and narcissism.  Very few do and fewer want to know, understand, or deal with such personality disorders.',\n",
              " \"I'm a complete weirdo and I feel comfortable being honest with her.\",\n",
              " 'no one else I would rather talk my problems over with!',\n",
              " 'Without Jessica’s support I feel like I would be in a very bad pace',\n",
              " \"I cannot imagine how I would have been able to function for the last few months without Leslie's support. PTSD, depression and anxiety have been the issues she has helped me with.\",\n",
              " \"I did not feel like a diagnosis or a potential disorder in Lee's mind. I felt like a person with a personality that needed a some help in the right direction\",\n",
              " 'I don’t think I would be hanging in here without Erin.',\n",
              " 'My past experience with therapists I’ve always felt like a number. I felt pitied and looked down upon. Talking with Desarae is like talking to my really insightful friend. She pushes me to try new things and further my goals rather than say ‘oh that sucks’ when I talk about my issues with myself, my relationships or my life.',\n",
              " 'I feel that Latonia Jennings has and is addressing my concerns and issues and giving me tools to try to deal with them.\\nRegarding Betterhelp when I check in on my phone to see the message that has been sent to me by Betterhelp I am asked to put in a pin # but I never had a pin # so cannot access that message on my phone, I have to go to my computer which is not always convenient to answer in time.   Can you inform me as to how I remedy this situation.',\n",
              " 'Without your help life is too complicated and stressful. Thanks Robert!',\n",
              " 'Darius Jones seems to have issues around scheduling or potentially time management/communication. Over a week we had two scheduled sessions that he did not show up to and for no apparent reason where I messaged repeatedly and waiting around for 30min. after the start time to which I arrived on the session tab 5 minutes early. Was not helpful. If you can get an audience with him maybe he is helpful, but I’ll never know.',\n",
              " 'These are a lot of questions that I think are for BetterHelp metrics so I don’t feel like responding to them',\n",
              " \"Struggling with problems in my life and one of the hardest things that I have ever done is ask for help.   Only to be told that she can't help me.  I guess I'm  a lost case.................\",\n",
              " 'Literally my anchor is the craziest year of my life (divorce, job loss, pandemic, single parenting!)',\n",
              " \"I wouldn't have made it through the year without her! I mean, I wouldn't be dead, but I'd be a wreck.\",\n",
              " 'I’m happy. The beginning was rough and I almost cancelled because the first counselor I had sucked',\n",
              " \"She has increased the negativity in my life to the point where I dread her messages. She will never acknowledge your work but will blame you for anything that has gone wrong. She is incredibly negative and mocks her clients. She will never admit fault and shows no regard for the life of her client. Please don't allow this counselor to have more clients. Lives will be lost.\",\n",
              " 'Things started great with Rebecca . However , her responsiveness was not given in a timely manner ; she actually did not respond effectively as it seemed like she was rushed or just responding with what I wanted to hear . Not a pleasant experience the least .',\n",
              " 'Dr. Foxman cancelled my first appointment with less than 24 hours notice.',\n",
              " \"Stephanie is great; she has techniques that one can use to clam him/her self down, but I wanted to have a different approach. I'm a depersonalized and derealized, so the things are different. I need someone who could take me to the root of the negative thoughts that keep running in my mind. Breathing and meditation techniques do not work for me.\",\n",
              " nan,\n",
              " 'Lisa made me believe in therapy. I never understood why people needed it but I honestly am mad I didn’t meet her sooner',\n",
              " 'Fantastic non-judgemental empathetic counselor.',\n",
              " \"He provides some really useful resources and is a good listener. On the other hand, he isn't timely in his replies (a couple days for me) and I don't feel like I've gotten much out of the actual sessions. For me, it's too much talking about issues without any practical guidance in resolving them.\",\n",
              " \"Bullshit. Doesn't help with problems, doesn't listen and lucky to get even a small message back. No empathy or saying I'm sorry, you went through what you did. Judged my issue and refused to handle or listen to it, especially when the mental health care system knows that with covid a lot of people can't get proper help so they come here for at least a little in the mean time. Or even when they can't get help for maybe years when their told they're on a waiting list that could take a few years to be seen.\",\n",
              " 'Melissa is great! I’m an awkward person and don’t really like talking to ppl not even my therapist',\n",
              " 'Courtney is the opposite of what I expected from an online counseling service. She is warm, understanding and close. She responds quickly and has a good balance of listening and recommending worksheets to grow.',\n",
              " \"I've been having some relationship problems and needed some guidance while I was in a tough spot. Priscilla has been helping me step by step to get through this rough patch in my life and I'd probably be in such an awful position without her.\",\n",
              " 'I was super intimidated at first',\n",
              " \"Great to share what's stressing me out with her.\",\n",
              " 'I have only had one session with Danielle and she has been very nice and helpful. However the site has been more of an issue. I’ve had trouble getting on the app. I’ve had problems during sessions with clarity and being able to hear my counselor. I also had to cancel a session bc the app wasn’t working',\n",
              " 'She is very judgmental without knowing and bothering to ask full details to understand and has been very rude through messages. She tries to put words in your mouth and insists certain things are going on when you know they are not. Does not help when you are trying to recover from abuse and people gaslighting you. She has made me feel very forced to agree with her and have felt very battled when expressing the truth and how I really feel because it doesn’t align with what she would expect.',\n",
              " 'This is my first time getting professional help.  I feel like Brenda is doing a good job with understanding what my issues are without taking my side per se, she agrees with my concerns and whats hurting my mind but doesn’t let me be ok with it.   Not sure it that makes sense.  Kind of a tough love type of helping.',\n",
              " \"Kym get's back to me in a very timely manner and checks in with me if I haven't checked in with her.  She takes time on weekends and at night to respond to my needs.  If she sees something isn't working, she will change what we are doing so we aren't working on things that aren't necessary.\",\n",
              " 'I was hesitant to have counseling in the past. I met a few therapists who did not quite understand me or help. Given my horrible work schedule, it is difficult for me to see a therapist in person. Jackie has been a fantastic help.',\n",
              " 'I was worried that my therapist would be too CLINICAL. That was not the case. Very laid back. And that is what I needed . I don\\'t want a \"how does that make you feel\" I want a \"so here is the plan of action\"',\n",
              " \"Tiffany's guidance has been like having superpowers.  Without her I'd be in an awful place.\",\n",
              " 'Cant says enough good thugs about Karen- \\nIt’s unfortunate that in today’s vernacular “Karen”  is a pejorative, an insult or something that one shouldn’t want to be- every time i hear Karen used as an adjective I think of my counselor Karen and BetterHelp and she’s absolutely the opposite of the modern definition of the name.',\n",
              " \"Dr. Tanjua is personable, relatable, funny, tells it like it is. She is able to give examples that connect in my mind and help unlock further pathways and realizations. I don't value myself, because I don't think I'm important. I feel like a failure (especially compared to gross expectations of myself when I don't even try) and I feel stagnant and stuck and unworthy because I have stopped growing. I'm no longer challenging myself to learn new things that are important to me and make me happy. I've begun my healing journey and I'm ready to open all the boxes of emotions I've been avoiding.\",\n",
              " 'Jim was very good about sending me the appointment times he had available and checking in to see if I got his e-mail.  The only issue holding up the first appointment was that I was not getting some of my questions answered by the Customer Service department.  They have a policy that they do not speak to people on the phone so e-mailing back and forth to get simple questions (basically yes/no) answered about billing was taking days not minutes.  I work 12/day and we are not allowed access to  personal e-mail at work so I finally decided that this system of playing \"e-mail tag\" was only making my mental health situation worse.  (I am actually taking time off work to type this.)   I am sorry that I did not get to set up an appointment.  :(',\n",
              " 'James retraumatized me through our first session and went way too deep too fast. I have been having crazy panic attacks and feel way worse than before our session. I feel discouraged about therapy now, and doubtful I will find someone safe to talk with ever.',\n",
              " 'Abayome is a wonderfull counselor, but Better Help is very annoying attempting to take up too much of your clients time by constant text and redundant emails and surveys.',\n",
              " 'Emmanuel did a very good job of explaining things technically but doesn’t listen very well or open mindedly. Also,  if you are not making the progress he thinks you should, he will drop you like a fly.  He left Me high and dry during a very hard time in my life.  I will never seek counselling from him or BetterHelp EVER again!!',\n",
              " 'Sheaundra gets at the heart of my problems.',\n",
              " 'He is very under standing',\n",
              " 'She is never on time for our appointments. And even when I do finally get ahold of her when I talk she seems to focus on weird aspects of the conversation opposed to what I am trying to talk to her about. Brought up some past traumas and glazed right over them and asked me unrelated superficial questions opposed to trying to talk about the problem.',\n",
              " 'My two previous councilors where terrible at responding back to me and keeping appointments. Mrs. Pace not only checks in with me on an almost daily basis but also keeps her appointments. I would absolutely recommend her to friends or family.',\n",
              " 'It’s no stretch to say that I don’t know what my life would be like had I not worked with Eleanor during this pandemic.',\n",
              " 'Instead of finding my defense mechanism of humor deflection funny, she acknowledges that it can be humorous but what is the real underlining message. It makes me break the habit of thinking humor is an aid to hide my feelings or thoughts about myself when im hurting',\n",
              " 'I had issues at work that were impacting my mental health',\n",
              " 'Cyndi rules, doesn’t even feel like therapy',\n",
              " 'Its just the start and we have never done this before so cant grade to high right now.',\n",
              " \"Probably shouldn't offer live chat if she is unable to do it..\",\n",
              " 'I started therapy with Keith by stating what brought me here and what I was currently struggling with. 3 days later, he replied with a \"Ok thank you for talking about that\". I let him know I thought his response wasn\\'t helpful, to which he replied that he was already working 10 hours a day before logging onto BetterHelp. That did not really help either.\\nIf his schedule is making it hard for him to stay here, then he shouldn\\'t be here, and I\\'m not paying to hear him trying to justify his life choices.',\n",
              " 'I couldnt get through the difficult times im faced with, without Dianes help.',\n",
              " 'Just two sessions in. Of anyone tries to analyze their therapy that early they don’t understand the process.',\n",
              " 'Im having problems getting on, would you send the number again.  Thank you',\n",
              " \"Debra is a nice person. She may have experience working with some addictions. However she was not helpful to me. I am a food addict and joined BetterHelp looking for support directly related to food addiction. She sent me a worksheet which ended up being a trigger for binge foods.  Very disappointing.  Also, I don't know if it was a fluke of the website or what, but TWICE I left a voice recording, telling her how I felt about this. I checked, the second time, to be sure it processed and was visible. I was able to play it on the site. Not only did she not reply, but the voice recording was deleted.  That doesn't seem professional at all.\",\n",
              " 'Brittany is very responsive.\\n\\nI\\'m uncomfortable with the kind of therapist who just sits and listens to you talk, interjecting rarely and then only to ask, \"...and how do you feel about that?\"\\n\\nThat\\'s not Brittany. She actively listens, responds, and participates. It\\'s a conversation, not and endless one-way drone.',\n",
              " 'We were doing well until she brought up some really triggering stuff as unhelpful advice to me. I got upset. I was called toxic and yes I did cuss and got upset because felt like I was being spoken down as a low priority patient. I feel like the ending if the contact was mutual because I do have a lot of very heavy trauma and toxic thinking to work through. But I thought that was the point of going to someone like her.',\n",
              " \"Jack is great...the number of times I'm asked for feedback from Better Help is not. If someone is not doing their job, trust me they will let you know about it. People don't want their therapy to feel and operate like a Best Buy or a customer service survey after a lengthy call to AT&T might. And if they do, they are wrong.\",\n",
              " 'If I schedule an appointment at 5pm, I would expect my therapist to be present, just as if I was doing an in person meeting. 30 mins waiting and no call. Unbelievable. Not a good look.',\n",
              " 'Completely unhelpful, and unwilling to even help. Non-responsive in communication.',\n",
              " 'Sorry Kari, I have a problem with the payment system of this page, so I cant start the live session. I dont want to waste ur time since I cant response you.',\n",
              " 'I don’t stop talking about her to friends and coworkers. I would be a hotter mess without her these past 9 months.',\n",
              " 'My life is a mess, so many things are out of my control; Breanne makes me feel validated for my thoughts and emotions during this rough time.',\n",
              " 'Honestly Mr. Schroeder has been very responsive.  I’m not sure if online counseling works for me.  I need to be called out on my crap.',\n",
              " 'Brooke is unbelievable in her communication skills. She absolutely blows my mind with the amount she can offer to me. She’s a unicorn - just one of a kind.',\n",
              " 'She just ghosted me after one session.',\n",
              " 'I don’t make myself a priority that includes my mental health. When I don’t schedule, or forget an appt, or don’t reach out in a while, she reaches out and pushes me like I need.\\nI feel like we are just having a conversation over tea rather than an appt.',\n",
              " 'I’ve always struggled to stay consistent with therapy.  My time with siouneh has been the longest I’ve done therapy for.  If it wasn’t for her I would have stopped along time ago. Amazing is an understatement!',\n",
              " 'Best damn counselor yall had I swear to god',\n",
              " 'I use BetterHelp because of Elizabeth. I would never think of getting another counselor.',\n",
              " 'I had seen other counsellors face-to-face and doing they didn’t truly understand that though I had an immediate issue that I needed support with, they didn’t see the underlying causes. Straight away Mark understood, was supportive and could give me practical tips on how to manage and develop. I wouldn’t be where I am today if I hadn’t spoke to Mark.',\n",
              " \"First session and Erin had astute observations in a short time. What I'm going through is so complicated I didn't think this would be helpful. I was happily wrong.\",\n",
              " 'Although I didn’t have many sessions with Mrs. Simmons I didn’t think she was the right therapist for me. I don’t think she truly understood my struggles, and the many techniques we tried seemed very unhelpful.',\n",
              " 'Yvette is very non judgemental and share related stories to help me understand how i am. She kicks my butt when needed though',\n",
              " \"She's great. I would send a longer review but it's late and I didn't expect this popup. All I can say is that Stephanie will really hold you accountable to the things you say you want to do to improve yourself, and she's a no-BS counselor. I personally really benefit from the kind of straight-shooting she does. Counselors who don't tell me how it really is, who aren't blunt or assertive enough, tend to have a hard time helping me. I'm not a man of action, so I need someone who doesn't vacillate to help me explore my problems (and their solutions). I'm definitely heartbroken to have to leave Stephanie soon and I don't think I'll be able to find another counselor who can provide the same style (or quality) of service.\",\n",
              " 'Jordan was erroneously matched with me even though she wasn’t accepting new patients. This is after I described my current situation. How awkward! I would recommend that she and other counselors please update their settings. It is very disappointing, especially when people in need are seeking emotional support for mental health issues. It also shows a lack of professionalism to have automated responses. Please be very cautious. Patients expect confidentiality and true connection!',\n",
              " 'This place is not legitimate!',\n",
              " 'Only gives the basics, didn’t really try to get to know me or tried to set any call, video anything. invalided my feelings and left me feeling worse.',\n",
              " \"Edlyne definitely helped me with the relationship issues I was experiencing and I'm really grateful for that. However, I was cancelled on twice, the first one for a very valid reason, the second for no reason given. And on the final rebooked appointment, she did not show. I am definitely unhappy with this aspect.\",\n",
              " \"Dr. D is one unique and caring Doctor. He has unfortunately but fortunate in the same breath to have lived thru some of the very same tradegies as I'm living through today. My best friend was stolen from me that awful day in San Bernardino December 2 2015 by 2 individuals that saw fit to just terrorize an entire community with their complete and total mental without disregard to any human decency! They saw fit to kill my best friend as well as 13 other unsuspecting souls celebrating at their company Christmas party. He immediately heard me as well as felt my pain. He has given me hope! I have been suffering immensely and know in my heart I will NEVER Be the same 55 year old I was in December 2015. Terrorism works and I hope that another person never has to feel the many uncertain and uncharted emotions this old dog is experiencing! Dr. D gets me. The first  one that has since this tragedy ROCKED my world.\",\n",
              " \"I have been struggling for years trying to understand what the heck is wrong with me. Amanda figured it out and recommended some reading material in like two sessions. Just like that?! I wish I'd come here sooner, y'all!\",\n",
              " 'I have recommended this site to a dear friend, I hope she uses it. We went through a terrible situation at work together and neither of us have recovered from it.',\n",
              " 'She always makes me feel like I’m being listened to. She doesn’t placate me',\n",
              " \"I have never felt understood by a therapist until Emily. We've barely begun our process and my levels of depression and anxiety are already going down.\",\n",
              " 'I have been working with Liz for almost a year. I unfortunately was a victim of a violent attack that left me extremely traumatized and with PTSD. 4 years later I what is involved in a terrible car accident where my son passed away and I was in the hospital for a lengthy stay. I was diagnosed with chronic PTSD and when Covid hit needless to say PTSD was off the charts. I was  struggling incredibly with it. I desperately needed help. Liz was and is a God send. She taught me to regonize the signs. Taught me tools to relax my nervous system. Tools to help me process and stop all the racing thoughts.  We addressed all the trauma  I experienced. In the beginning I honestly didn’t think I would be able to mange let alone feel like I was in the drives seat regarding my mental health. Liz is AMAZING! I do not struggle with mental health any more.  I couldn’t have made it to this point with Liz.',\n",
              " 'I have never felt comfortable opening up to a therapist before Dr Vevaina',\n",
              " 'Unlike my first counselor, Joyce was understanding of the difficulties of struggling with depression and trying to still get things she done. She never made me feel like I \"wasn\\'t trying hard enough\" or didn\\'t really want help.',\n",
              " 'Useful tool!',\n",
              " 'She tells me what I need to hear, not what I want to.',\n",
              " 'Not satisfied. The  counselor was very judgmental and not helpful. She barely communicated with me during the live sessions and she constantly had technical issues so we were wasting most of the time.',\n",
              " 'For the brief time I have been working with Tracy, she seems to be a very good counselor. However, she appears to be quite busy and unresponsive at times. I would like to provide a better testimonial, but unfortunately I have not have as much interaction with her as I would like because of the lack of response I get from here.',\n",
              " 'For a year I\\'ve been going to therapy and various psychologists but had never felt like \"Oh right. This is it.\" but Savili made me feel that way.',\n",
              " 'Pat specialties and qualifications made me interested in him being my counselor, I asked him can I schedule a video session. In response he says “I don’t do Christian counseling this is how you can change your counselor and make sure you have the type of counselor you want described.” I did answer on the questionnaire I like Christian counseling but not once did I say it was a requirement. So it really took me aback when I read his response  because if I was not interested in his way counseling I would not have tried to schedule a session with him. Communication is so vital. I feel like he made assumptions  rather than asking me a simple question.',\n",
              " 'I was skeptical about reaching out and using an online service',\n",
              " 'It took me a bit to understand the dynamic bit now I do not want any other therapist. still oraying he doesn’t retire any time soon!',\n",
              " 'Kelsi Yonting was able to help identify underlying problems I was unable to identify and work around my insane schedule.',\n",
              " 'I hate talking to people. Literally anyone who is a person besides my husband and grandparents. And I still don’t like building relationships but he has been an excellent and helpful and kind counselor.',\n",
              " \"This counselor is horrible!  He wanted me to fill in the questionnaire that has to be submitted before the scheduled meeting. The scheduled meeting is the following day.  Been working on the questionnaire and was going to send it later tonight.  He canceled and asked me to find another counselor.  Don't take this guy.\",\n",
              " \"I don't know how I would have made it these last few months without her.\",\n",
              " 'I was unable to work with her because she doesn’t respond, would not recommend if you want a fast response.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(lis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwvWxzU-hfse",
        "outputId": "743e59d3-74d6-4549-e2a5-333874dda7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data = pd.DataFrame(lis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDRDBqGkhxDy",
        "outputId": "48d92976-2c72-4b21-b643-47d341f52115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data['Review'] = review_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6W_0xpV1h_EI",
        "outputId": "54ccaf47-d4e9-4092-a44f-71cc958ee57e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "Yq8HTPuuin2o",
        "outputId": "46c5d4dc-b3d8-4c1a-8822-ca7cf83ec7bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0  \\\n",
              "0    I love my therapist. took me a few tries to fi...   \n",
              "1    Usually therapy is stressful and feels like ho...   \n",
              "2    She's knowledgeable, empathetic, and doesn't g...   \n",
              "3           She gets me me and I am a complicated mess   \n",
              "4    She has mad it easyer for me to talk about thi...   \n",
              "..                                                 ...   \n",
              "169  Kelsi Yonting was able to help identify underl...   \n",
              "170  I hate talking to people. Literally anyone who...   \n",
              "171  This counselor is horrible!  He wanted me to f...   \n",
              "172  I don't know how I would have made it these la...   \n",
              "173  I was unable to work with her because she does...   \n",
              "\n",
              "                                                Review  \n",
              "0    I love my therapist. took me a few tries to fi...  \n",
              "1    Usually therapy is stressful and feels like ho...  \n",
              "2    She's knowledgeable, empathetic, and doesn't g...  \n",
              "3           She gets me me and I am a complicated mess  \n",
              "4    She has mad it easyer for me to talk about thi...  \n",
              "..                                                 ...  \n",
              "169  Kelsi Yonting was able to help identify underl...  \n",
              "170  I hate talking to people. Literally anyone who...  \n",
              "171  This counselor is horrible!  He wanted me to f...  \n",
              "172  I don't know how I would have made it these la...  \n",
              "173  I was unable to work with her because she does...  \n",
              "\n",
              "[174 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a23a971a-ef9f-4307-974b-86ad75dcb2b5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love my therapist. took me a few tries to fi...</td>\n",
              "      <td>I love my therapist. took me a few tries to fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Usually therapy is stressful and feels like ho...</td>\n",
              "      <td>Usually therapy is stressful and feels like ho...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She's knowledgeable, empathetic, and doesn't g...</td>\n",
              "      <td>She's knowledgeable, empathetic, and doesn't g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>She gets me me and I am a complicated mess</td>\n",
              "      <td>She gets me me and I am a complicated mess</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>She has mad it easyer for me to talk about thi...</td>\n",
              "      <td>She has mad it easyer for me to talk about thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Kelsi Yonting was able to help identify underl...</td>\n",
              "      <td>Kelsi Yonting was able to help identify underl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>I hate talking to people. Literally anyone who...</td>\n",
              "      <td>I hate talking to people. Literally anyone who...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>This counselor is horrible!  He wanted me to f...</td>\n",
              "      <td>This counselor is horrible!  He wanted me to f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>I don't know how I would have made it these la...</td>\n",
              "      <td>I don't know how I would have made it these la...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>I was unable to work with her because she does...</td>\n",
              "      <td>I was unable to work with her because she does...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>174 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a23a971a-ef9f-4307-974b-86ad75dcb2b5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a23a971a-ef9f-4307-974b-86ad75dcb2b5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a23a971a-ef9f-4307-974b-86ad75dcb2b5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text ):\n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation}\n",
        "    delete_dict[' '] = ' '\n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    #print('cleaned:'+text1)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>3))])\n",
        "\n",
        "    return text2.lower()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPsc235bZW9X",
        "outputId": "32d6bf3a-61fe-43fc-8c97-523d1e35d2fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords') # run this one time"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q8wFS18mhrZA",
        "outputId": "44a98560-ba88-4617-a52b-fa37d329d382"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data.dropna(axis = 0, how ='any',inplace=True)\n",
        "\n",
        "review_data['Review'] = review_data['Review'].apply(clean_text)\n",
        "review_data['Num_words_text'] = review_data['Review'].apply(lambda x:len(str(x).split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kys6-c_pi1xA",
        "outputId": "f0899bbf-a889-4207-e63a-7ecf48f1c90b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "# function to remove stopwords\n",
        "def remove_stopwords(text):\n",
        "    textArr = text.split(' ')\n",
        "    rem_text = \" \".join([i for i in textArr if i not in stop_words])\n",
        "    return rem_text\n",
        "\n",
        "# remove stopwords from the text\n",
        "review_data['Review']=review_data['Review'].apply(remove_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzIq_wgri6zG",
        "outputId": "f91bb465-101f-42b6-93ed-416fa2ee9eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "review_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "4fUbrNEii9yi",
        "outputId": "7d0f1334-6779-44b7-c531-de5b2544cc5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     0  \\\n",
              "0    I love my therapist. took me a few tries to fi...   \n",
              "1    Usually therapy is stressful and feels like ho...   \n",
              "2    She's knowledgeable, empathetic, and doesn't g...   \n",
              "3           She gets me me and I am a complicated mess   \n",
              "4    She has mad it easyer for me to talk about thi...   \n",
              "..                                                 ...   \n",
              "169  Kelsi Yonting was able to help identify underl...   \n",
              "170  I hate talking to people. Literally anyone who...   \n",
              "171  This counselor is horrible!  He wanted me to f...   \n",
              "172  I don't know how I would have made it these la...   \n",
              "173  I was unable to work with her because she does...   \n",
              "\n",
              "                                                Review  Num_words_text  \n",
              "0    love therapist took tries find however impress...              57  \n",
              "1    usually therapy stressful feels like homework ...              28  \n",
              "2    shes knowledgeable empathetic doesnt give answers               6  \n",
              "3                                gets complicated mess               3  \n",
              "4                  easyer talk thing dont like talking               8  \n",
              "..                                                 ...             ...  \n",
              "169  kelsi yonting able help identify underlying pr...              13  \n",
              "170  hate talking people literally anyone person be...              19  \n",
              "171  counselor horrible wanted fill questionnaire s...              29  \n",
              "172           dont know would made last months without               9  \n",
              "173  unable work doesn’t respond would recommend wa...              11  \n",
              "\n",
              "[173 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6aa221ff-e931-4560-bc3d-14a87d04202b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>Review</th>\n",
              "      <th>Num_words_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I love my therapist. took me a few tries to fi...</td>\n",
              "      <td>love therapist took tries find however impress...</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Usually therapy is stressful and feels like ho...</td>\n",
              "      <td>usually therapy stressful feels like homework ...</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>She's knowledgeable, empathetic, and doesn't g...</td>\n",
              "      <td>shes knowledgeable empathetic doesnt give answers</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>She gets me me and I am a complicated mess</td>\n",
              "      <td>gets complicated mess</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>She has mad it easyer for me to talk about thi...</td>\n",
              "      <td>easyer talk thing dont like talking</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>Kelsi Yonting was able to help identify underl...</td>\n",
              "      <td>kelsi yonting able help identify underlying pr...</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>I hate talking to people. Literally anyone who...</td>\n",
              "      <td>hate talking people literally anyone person be...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>This counselor is horrible!  He wanted me to f...</td>\n",
              "      <td>counselor horrible wanted fill questionnaire s...</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>I don't know how I would have made it these la...</td>\n",
              "      <td>dont know would made last months without</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>I was unable to work with her because she does...</td>\n",
              "      <td>unable work doesn’t respond would recommend wa...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>173 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6aa221ff-e931-4560-bc3d-14a87d04202b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6aa221ff-e931-4560-bc3d-14a87d04202b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6aa221ff-e931-4560-bc3d-14a87d04202b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_md\n",
        "!python -m spacy download en_core_web_lg\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hwx1eZUjBPL",
        "outputId": "71960790-88b5-462c-8426-32a05271be57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-27 15:51:11.129145: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-md==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.5.0/en_core_web_md-3.5.0-py3-none-any.whl (42.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-md==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-md==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "2023-06-27 15:51:24.094472: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0-py3-none-any.whl (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.3)\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "2023-06-27 15:51:53.282293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m100.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.3)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.9)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])\n",
        "\n",
        "def lemmatization(texts,allowed_postags=['NOUN', 'ADJ']):\n",
        "       output = []\n",
        "       for sent in texts:\n",
        "             doc = nlp(sent)\n",
        "             output.append([token.lemma_ for token in doc if token.pos_ in allowed_postags ])\n",
        "       return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NUY_OWnjCTY",
        "outputId": "28acaf38-a115-48ee-e3a3-74d0aa0755e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_list=review_data['Review'].tolist()\n",
        "print(text_list[1])\n",
        "tokenized_reviews = lemmatization(text_list)\n",
        "print(tokenized_reviews[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JmK5qfMjIp9",
        "outputId": "e4ed8530-21ca-41a2-c3f8-5dbf29a9cea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usually therapy stressful feels like homework feel like disappoint therapists anita doesnt stress doesnt make feel like anything encourages taking steps towards better health consoles mess\n",
            "['therapy', 'stressful', 'homework', 'disappoint', 'therapist', 'step', 'well', 'health', 'console', 'mess']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(tokenized_reviews)\n",
        "doc_term_matrix = [dictionary.doc2bow(rev) for rev in tokenized_reviews]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEaiIYcDjZfw",
        "outputId": "b260d22f-abaf-4560-df17-6a1a362e1e1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the object for LDA model using gensim library\n",
        "LDA = gensim.models.ldamodel.LdaModel\n",
        "\n",
        "# Build LDA model\n",
        "lda_model = LDA(corpus=doc_term_matrix, id2word=dictionary, num_topics=4, random_state=20,\n",
        "                chunksize=200, passes=25,iterations=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls7DBEzujbIx",
        "outputId": "8104ac04-27c7-4691-99b9-ab214134e90d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model.print_topics()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ik-0P98jjqS",
        "outputId": "b5b750b9-8227-4812-ae92-15b254119e02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.023*\"therapy\" + 0.021*\"time\" + 0.019*\"thing\" + 0.014*\"month\" + 0.012*\"appointment\" + 0.012*\"issue\" + 0.012*\"service\" + 0.012*\"counselor\" + 0.011*\"friend\" + 0.010*\"well\"'),\n",
              " (1,\n",
              "  '0.015*\"counselor\" + 0.015*\"session\" + 0.012*\"therapist\" + 0.010*\"good\" + 0.008*\"counseling\" + 0.008*\"year\" + 0.008*\"message\" + 0.008*\"chat\" + 0.008*\"response\" + 0.008*\"experience\"'),\n",
              " (2,\n",
              "  '0.020*\"counselor\" + 0.017*\"work\" + 0.016*\"good\" + 0.013*\"time\" + 0.009*\"email\" + 0.009*\"meeting\" + 0.009*\"appointment\" + 0.009*\"mind\" + 0.009*\"therapist\" + 0.009*\"first\"'),\n",
              " (3,\n",
              "  '0.041*\"session\" + 0.025*\"time\" + 0.022*\"therapist\" + 0.019*\"problem\" + 0.017*\"help\" + 0.013*\"year\" + 0.013*\"life\" + 0.012*\"issue\" + 0.010*\"many\" + 0.010*\"thing\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(lda_model, doc_term_matrix, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "FZLc9RZ4jkuU",
        "outputId": "6ca56d12-fccc-4feb-961e-9e3a28f835d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3     -0.077691  0.073158       1        1  32.594273\n",
              "0     -0.071091 -0.070983       2        1  25.753168\n",
              "2      0.068492 -0.068831       3        1  21.982904\n",
              "1      0.080290  0.066656       4        1  19.669655, topic_info=         Term       Freq      Total Category  logprob  loglift\n",
              "55    session  25.000000  25.000000  Default  30.0000  30.0000\n",
              "28    therapy  14.000000  14.000000  Default  29.0000  29.0000\n",
              "124     month   6.000000   6.000000  Default  28.0000  28.0000\n",
              "57       work  11.000000  11.000000  Default  27.0000  27.0000\n",
              "46    problem  12.000000  12.000000  Default  26.0000  26.0000\n",
              "..        ...        ...        ...      ...      ...      ...\n",
              "59      point   1.478002   4.083911   Topic4  -5.2500   0.6097\n",
              "54     mental   1.476341   9.706915   Topic4  -5.2512  -0.2572\n",
              "413  schedule   1.474284   3.437300   Topic4  -5.2526   0.7796\n",
              "304      much   1.473991   4.131859   Topic4  -5.2528   0.5953\n",
              "0        able   1.473971   9.056511   Topic4  -5.2528  -0.1894\n",
              "\n",
              "[254 rows x 6 columns], token_table=      Topic      Freq    Term\n",
              "term                         \n",
              "448       3  0.734902   12day\n",
              "0         1  0.441671    able\n",
              "0         2  0.331253    able\n",
              "0         3  0.110418    able\n",
              "0         4  0.110418    able\n",
              "...     ...       ...     ...\n",
              "222       1  0.572063    year\n",
              "222       2  0.190688    year\n",
              "222       3  0.095344    year\n",
              "222       4  0.190688    year\n",
              "83        2  0.724316  youper\n",
              "\n",
              "[324 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 3, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2261406699708044963264140478\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2261406699708044963264140478_data = {\"mdsDat\": {\"x\": [-0.07769147284890933, -0.07109079081862649, 0.06849231927033876, 0.08028994439719711], \"y\": [0.07315770705423227, -0.07098339371442491, -0.06883079480551361, 0.06665648146570631], \"topics\": [1, 2, 3, 4], \"cluster\": [1, 1, 1, 1], \"Freq\": [32.59427303276417, 25.753168270456182, 21.982903595835563, 19.669655100944084]}, \"tinfo\": {\"Term\": [\"session\", \"therapy\", \"month\", \"work\", \"problem\", \"thing\", \"appointment\", \"good\", \"service\", \"meeting\", \"reason\", \"mind\", \"last\", \"tool\", \"pandemic\", \"counselor\", \"client\", \"experience\", \"ptsd\", \"right\", \"happy\", \"chat\", \"bad\", \"email\", \"phone\", \"help\", \"thought\", \"questionnaire\", \"anxiety\", \"friend\", \"client\", \"third\", \"party\", \"disorder\", \"complicated\", \"live\", \"unable\", \"emotional\", \"cautious\", \"care\", \"judgmental\", \"progress\", \"hassert\", \"wrong\", \"personality\", \"mean\", \"timely\", \"manner\", \"awkward\", \"intense\", \"difficult\", \"session\", \"problem\", \"comfortable\", \"hard\", \"great\", \"help\", \"couple\", \"thank\", \"week\", \"many\", \"therapist\", \"year\", \"time\", \"helpful\", \"patient\", \"life\", \"right\", \"issue\", \"health\", \"mental\", \"able\", \"thing\", \"therapy\", \"work\", \"response\", \"first\", \"counselor\", \"friend\", \"message\", \"people\", \"last\", \"food\", \"aspect\", \"specific\", \"goal\", \"past\", \"month\", \"voice\", \"recording\", \"appt\", \"worksheet\", \"briley\", \"less\", \"unresponsive\", \"solution\", \"trigger\", \"scared\", \"service\", \"conversation\", \"need\", \"addict\", \"fluke\", \"visible\", \"telling\", \"binge\", \"website\", \"color\", \"youper\", \"unheard\", \"rematch\", \"therapy\", \"anxiety\", \"thing\", \"appointment\", \"well\", \"reason\", \"negative\", \"second\", \"online\", \"professional\", \"friend\", \"experience\", \"talk\", \"time\", \"issue\", \"right\", \"counselor\", \"life\", \"able\", \"good\", \"people\", \"therapist\", \"first\", \"problem\", \"happy\", \"concern\", \"different\", \"unbelievable\", \"step\", \"company\", \"important\", \"dear\", \"difficulty\", \"approach\", \"meeting\", \"mind\", \"phone\", \"feel\", \"hope\", \"12day\", \"access\", \"department\", \"emailing\", \"billing\", \"sorry\", \"checking\", \"policy\", \"convenient\", \"computer\", \"remedy\", \"jenning\", \"helping\", \"love\", \"sense\", \"email\", \"work\", \"tough\", \"contact\", \"type\", \"minute\", \"situation\", \"chronic\", \"emotion\", \"awful\", \"illness\", \"technique\", \"good\", \"counselor\", \"reason\", \"appointment\", \"first\", \"time\", \"person\", \"mental\", \"friend\", \"health\", \"therapist\", \"issue\", \"thing\", \"question\", \"message\", \"people\", \"kind\", \"pandemic\", \"interested\", \"christian\", \"toxic\", \"humor\", \"practical\", \"feeling\", \"mechanism\", \"empathetic\", \"knowledgeable\", \"useful\", \"upset\", \"ptsd\", \"traumatized\", \"chart\", \"violent\", \"seat\", \"sign\", \"victim\", \"needless\", \"covid\", \"nervous\", \"hospital\", \"regonize\", \"racing\", \"requirement\", \"assumption\", \"vital\", \"qualification\", \"specialty\", \"tool\", \"video\", \"chat\", \"support\", \"bad\", \"sure\", \"answer\", \"today\", \"other\", \"trauma\", \"thought\", \"questionnaire\", \"guidance\", \"counseling\", \"reply\", \"experience\", \"counselor\", \"message\", \"good\", \"session\", \"therapist\", \"response\", \"year\", \"life\", \"health\", \"point\", \"mental\", \"schedule\", \"much\", \"able\"], \"Freq\": [25.0, 14.0, 6.0, 11.0, 12.0, 13.0, 8.0, 11.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 17.0, 4.0, 6.0, 3.0, 7.0, 2.0, 4.0, 4.0, 4.0, 3.0, 11.0, 5.0, 3.0, 4.0, 9.0, 3.791643200455678, 2.3471878134080986, 2.347185639934107, 2.34710913364961, 2.347014152836187, 2.3469706833563593, 2.3469161291591756, 2.190497074379064, 1.6249518606831415, 1.6249216493946612, 1.6249137162145928, 1.624912086109099, 1.6249089345718117, 1.6248848090105072, 1.6248756804197435, 1.6248741589879496, 1.624871768166559, 1.624871007450662, 1.6248665518289798, 1.624871007450662, 1.6248176486641734, 18.961016740863688, 8.869123177499544, 3.082789218421971, 3.06971772849039, 3.0672921315160058, 7.962417640682775, 2.348035250917339, 2.34634233202545, 3.777665589217089, 4.529083799161059, 10.325816744550407, 5.987543531177322, 11.779363990651344, 3.8508190727346885, 3.0751279399497427, 5.973425513518889, 3.8001653919758938, 5.581274729844283, 3.7946425945637876, 4.029832041697431, 3.788856806798724, 4.510566670144066, 4.496338240006872, 3.908149665595014, 3.0607204155556578, 3.2766694015279763, 3.059946224119927, 2.5467390248524224, 2.3531766036439574, 2.3524139316203807, 2.951226893327167, 2.2569338258569465, 2.256886943821273, 2.256869942643501, 2.2568160197160227, 2.253322363548453, 5.03766500895139, 1.5624693727764611, 1.5624690293183243, 1.5624101262478625, 1.5623982769421427, 1.5623998225037583, 1.5623799019318239, 1.5623546577587686, 1.562347101679759, 1.5621166412699634, 1.4578221434480694, 4.346079765431733, 2.257731507379674, 2.2596617421085123, 0.8679989091785817, 0.867998651584979, 0.867998651584979, 0.867998651584979, 0.867998651584979, 0.8679984798559106, 0.8679918682867772, 0.867991353099572, 0.8679911813705036, 0.8679907520478326, 8.560455699892067, 2.9570412961251216, 7.125437459437097, 4.346254242165229, 3.6602144737224083, 2.9489078639874666, 2.2619174034219722, 1.5640559776394272, 1.5637566538732024, 1.563456128003499, 4.040579248074788, 2.9708647992152075, 2.961466067301567, 7.8322976601329755, 4.346091443008384, 2.9431728000191137, 4.337377223161393, 3.6488611215522164, 2.9525402772423055, 2.949260595493964, 2.2480976783713906, 2.950829168804748, 2.252539450725608, 2.2482056959554155, 2.192196358441766, 1.5176923872092123, 1.5176781681802751, 1.5176510494137454, 1.5176467983638569, 1.5176441597811676, 1.5176391757916432, 1.5176224647679437, 1.517578048626006, 1.5174455331398282, 2.877382631692273, 2.874912918295014, 2.209514256159727, 2.1952478793220336, 2.1949664305018333, 0.843140848194286, 0.843140848194286, 0.8431407749003225, 0.8431404084305045, 0.8431400419606865, 0.8431396754908685, 0.8431393090210506, 0.8431390891391598, 0.8431189332991714, 0.8431188600052079, 0.8431187134172807, 0.8431187134172807, 0.8431182003595356, 0.8431180537716083, 0.8431180537716083, 2.8806474380065987, 5.45713196331912, 1.5208450537592393, 1.518169237736354, 1.5179901072893307, 1.5155429684328583, 2.1946983211830067, 1.5143796466426964, 1.522679601667994, 1.529909464824821, 1.5155483921861643, 1.521773101926265, 4.910287753176198, 6.230204441963334, 2.1930178371857263, 2.875239223020934, 2.6775850459904955, 4.168290156040662, 2.2018617800088176, 2.6442216337625637, 2.2969362175880303, 2.1942497621258124, 2.855337859674216, 2.5437156737172635, 2.188325117872665, 1.5236989741136575, 1.523074802719692, 1.5214259817146842, 1.5205920429969133, 2.1238950465199697, 1.4704396180928623, 1.470439355767737, 1.470428600437601, 1.4704245343981595, 1.4704219111469068, 1.4704021055999492, 1.470401843274824, 1.470318555047552, 1.4703158006337367, 1.470214936623072, 1.4696682510620174, 2.1303007637538434, 0.8168850307684042, 0.8168850307684042, 0.8168850307684042, 0.8168849651871228, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168848340245602, 0.8168815549604944, 0.8168814237979318, 0.8168814237979318, 0.8168814237979318, 0.8168814237979318, 2.124481998987753, 2.1300305688748193, 2.134979857013215, 2.122248169383549, 2.1277053189644604, 1.4755794854347641, 1.4706418707644424, 1.470430830201166, 1.4883549813603496, 1.4719573001050894, 2.1295970766053167, 1.470279993254138, 1.4825331998553186, 2.141486307095191, 1.4711098587879172, 2.131583664778957, 4.105288264542124, 2.136489144621434, 2.7717946911190663, 4.09756147797741, 3.4122370882196598, 2.134177797942714, 2.1381503184771815, 2.1218525830946477, 1.4789115391758945, 1.478002057966597, 1.4763410152734118, 1.4742843862913253, 1.473991369126403, 1.473971038929195], \"Total\": [25.0, 14.0, 6.0, 11.0, 12.0, 13.0, 8.0, 11.0, 6.0, 4.0, 5.0, 4.0, 3.0, 3.0, 2.0, 17.0, 4.0, 6.0, 3.0, 7.0, 2.0, 4.0, 4.0, 4.0, 3.0, 11.0, 5.0, 3.0, 4.0, 9.0, 4.297390319494751, 2.8528922697100465, 2.85289189036418, 2.8528864379620607, 2.8528703636158106, 2.8528749219058858, 2.852868638830146, 2.842505139596821, 2.1306409638002997, 2.130640419864222, 2.130636629800462, 2.130635939364586, 2.1306355101920262, 2.1306324375214505, 2.130631784612178, 2.1306310792281837, 2.130632150087229, 2.1306318119079446, 2.130630370143756, 2.130637046593587, 2.1306242393708983, 25.46785337181569, 12.112168758144069, 4.22991814655854, 4.269551542040538, 4.269447079922014, 11.337045766911963, 3.506482252074208, 3.527343704087764, 5.685356571511889, 7.0425352879447685, 19.54422086124903, 10.48834730982552, 25.239364194789594, 6.344757424532698, 4.882750313504998, 13.247255488247124, 7.075513409316099, 13.937005406468776, 8.322042927573833, 9.70691468166415, 9.056511417480722, 13.98785276218997, 14.02801194279066, 11.008661255463908, 6.923661541984504, 8.370252356349155, 17.73281615378678, 9.047852817098045, 6.85629030683074, 6.285401148756154, 3.4639969943702726, 2.769547376902342, 2.7695436122340005, 2.76954594085038, 2.7695448425167566, 2.7696648579120544, 6.222097657536079, 2.075082670081904, 2.0750826728965266, 2.075078132911631, 2.0750777593523346, 2.0750800355267405, 2.0750768081920983, 2.0750775039135454, 2.0750738201091794, 2.075052897373943, 2.072052621028244, 6.2285472709844125, 3.4231017220916096, 3.4915909095512196, 1.380613912883965, 1.380613842246618, 1.3806138441747886, 1.3806138482804442, 1.3806138924778124, 1.3806138934871648, 1.380613676751239, 1.3806136445618555, 1.3806136438053331, 1.3806137817968667, 14.02801194279066, 4.908208880760634, 13.98785276218997, 8.272497632811621, 6.890464874050959, 5.487691321422806, 4.166104359351218, 2.74964258356861, 2.7496237315233114, 2.749625030081734, 9.047852817098045, 6.14521847179838, 6.215659781535543, 25.239364194789594, 13.937005406468776, 7.075513409316099, 17.73281615378678, 13.247255488247124, 9.056511417480722, 11.521575219519951, 6.285401148756154, 19.54422086124903, 8.370252356349155, 12.112168758144069, 2.7098626553415364, 2.035294696580762, 2.035296282833901, 2.0352930470278743, 2.035295382807607, 2.0352950544432087, 2.035300339074909, 2.035292319944293, 2.035289716503196, 2.0352926564224307, 4.038265702335753, 4.1060257449855095, 3.363906984449879, 3.431821075912089, 3.431838745477399, 1.3607255635352273, 1.3607256330044413, 1.360725565412769, 1.360725481485311, 1.36072559796346, 1.3607255455636864, 1.360725559822019, 1.3607256562698775, 1.3607242254122942, 1.3607242278812761, 1.360724240701161, 1.3607242457719746, 1.3607244329379842, 1.3607243586303788, 1.3607244292824732, 4.8001872059957975, 11.008661255463908, 2.6889042005819297, 2.688819503017683, 2.688814817417898, 2.6889877076173585, 4.154120144946531, 2.688899225826904, 2.7295510829227045, 2.7565842982730486, 2.7298331109170384, 2.757175880890927, 11.521575219519951, 17.73281615378678, 5.487691321422806, 8.272497632811621, 8.370252356349155, 25.239364194789594, 6.224301571316497, 9.70691468166415, 9.047852817098045, 8.322042927573833, 19.54422086124903, 13.937005406468776, 13.98785276218997, 4.077418065930677, 6.85629030683074, 6.285401148756154, 3.410774196265277, 2.646832398899247, 1.9932751799924664, 1.9932752477562026, 1.9932751279352676, 1.9932750150317888, 1.9932751249589886, 1.9932749557234084, 1.9932751299938056, 1.9932743414646208, 1.993274642780161, 1.9932806291628116, 1.9933496478088686, 3.340837294984315, 1.3397184917006077, 1.339718510024099, 1.33971851572639, 1.3397184444428174, 1.3397183404486797, 1.3397183404486797, 1.339718355629528, 1.3397183619148132, 1.3397183619148132, 1.33971837139337, 1.3397184121460075, 1.339718433612141, 1.339718424088225, 1.3397183143917961, 1.3397183143917961, 1.33971832323673, 1.3397184230654955, 3.9959006361385825, 4.065516155024232, 4.090088865207011, 4.063484627003542, 4.090860227811856, 2.667626735267641, 2.667782774604399, 2.6677940882965627, 2.713531612526101, 2.6875853013673794, 5.384441729261925, 3.3423651831319026, 3.388429882705033, 6.133501536895596, 3.382108718136431, 6.14521847179838, 17.73281615378678, 6.85629030683074, 11.521575219519951, 25.46785337181569, 19.54422086124903, 6.923661541984504, 10.48834730982552, 13.247255488247124, 8.322042927573833, 4.083911199375985, 9.70691468166415, 3.4373003554290906, 4.131858888408642, 9.056511417480722], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.813, -5.2926, -5.2926, -5.2926, -5.2926, -5.2927, -5.2927, -5.3617, -5.6603, -5.6603, -5.6603, -5.6603, -5.6603, -5.6604, -5.6604, -5.6604, -5.6604, -5.6604, -5.6604, -5.6604, -5.6604, -3.2034, -3.9632, -5.02, -5.0242, -5.025, -4.0711, -5.2922, -5.2929, -4.8167, -4.6353, -3.8111, -4.3561, -3.6794, -4.7975, -5.0224, -4.3585, -4.8107, -4.4264, -4.8122, -4.7521, -4.8137, -4.6394, -4.6425, -4.7827, -5.0271, -4.959, -5.0274, -5.211, -5.29, -5.2904, -4.828, -5.0962, -5.0962, -5.0962, -5.0963, -5.0978, -4.2933, -5.4639, -5.4639, -5.464, -5.464, -5.464, -5.464, -5.464, -5.464, -5.4642, -5.5333, -4.4409, -5.0959, -5.095, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -6.0518, -3.7631, -4.826, -3.9465, -4.4409, -4.6127, -4.8288, -5.094, -5.4629, -5.4631, -5.4633, -4.5138, -4.8214, -4.8245, -3.852, -4.4409, -4.8307, -4.4429, -4.6158, -4.8275, -4.8287, -5.1001, -4.8281, -5.0982, -5.1001, -4.967, -5.3347, -5.3347, -5.3348, -5.3348, -5.3348, -5.3348, -5.3348, -5.3348, -5.3349, -4.695, -4.6959, -4.9591, -4.9656, -4.9658, -5.9225, -5.9225, -5.9225, -5.9225, -5.9225, -5.9225, -5.9225, -5.9225, -5.9226, -5.9226, -5.9226, -5.9226, -5.9226, -5.9226, -5.9226, -4.6939, -4.055, -5.3327, -5.3344, -5.3345, -5.3361, -4.9659, -5.3369, -5.3315, -5.3267, -5.3361, -5.332, -4.1606, -3.9225, -4.9666, -4.6958, -4.767, -4.3244, -4.9626, -4.7795, -4.9203, -4.9661, -4.7027, -4.8183, -4.9688, -5.3308, -5.3312, -5.3323, -5.3328, -4.8875, -5.2552, -5.2552, -5.2552, -5.2552, -5.2552, -5.2552, -5.2552, -5.2553, -5.2553, -5.2553, -5.2557, -4.8845, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -5.843, -4.8872, -4.8846, -4.8823, -4.8883, -4.8857, -5.2517, -5.255, -5.2552, -5.2431, -5.2541, -4.8848, -5.2553, -5.247, -4.8792, -5.2547, -4.8839, -4.2285, -4.8816, -4.6212, -4.2303, -4.4134, -4.8827, -4.8808, -4.8884, -5.2494, -5.25, -5.2512, -5.2526, -5.2528, -5.2528], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9958, 0.9259, 0.9259, 0.9259, 0.9259, 0.9258, 0.9258, 0.8605, 0.8501, 0.8501, 0.8501, 0.8501, 0.8501, 0.8501, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.85, 0.826, 0.8094, 0.8047, 0.7911, 0.7903, 0.7677, 0.72, 0.7133, 0.7122, 0.6796, 0.483, 0.5604, 0.359, 0.6217, 0.6587, 0.3246, 0.4994, 0.2059, 0.3357, 0.2419, 0.2496, -0.0107, -0.0168, 0.0854, 0.3047, 0.1832, -0.636, -0.1467, 0.0516, 0.1382, 1.1964, 1.1519, 1.1519, 1.1519, 1.1519, 1.1503, 1.1454, 1.0729, 1.0729, 1.0728, 1.0728, 1.0728, 1.0728, 1.0728, 1.0728, 1.0727, 1.005, 0.9967, 0.9404, 0.9215, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8925, 0.8627, 0.8499, 0.6821, 0.713, 0.724, 0.7355, 0.7458, 0.7924, 0.7922, 0.792, 0.5505, 0.6298, 0.6152, 0.1865, 0.1913, 0.4795, -0.0515, 0.0672, 0.2358, -0.0061, 0.3285, -0.534, 0.044, -0.3275, 1.3029, 1.2215, 1.2214, 1.2214, 1.2214, 1.2214, 1.2214, 1.2214, 1.2214, 1.2213, 1.176, 1.1585, 1.0946, 1.0681, 1.068, 1.0363, 1.0363, 1.0363, 1.0363, 1.0363, 1.0363, 1.0363, 1.0363, 1.0362, 1.0362, 1.0362, 1.0362, 1.0362, 1.0362, 1.0362, 1.0043, 0.8131, 0.945, 0.9433, 0.9432, 0.9415, 0.8768, 0.9408, 0.9312, 0.9261, 0.9264, 0.9206, 0.662, 0.4689, 0.5977, 0.4581, 0.3751, -0.286, 0.4757, 0.2144, 0.144, 0.1818, -0.4086, -0.186, -0.3401, 0.5306, 0.0105, 0.0963, 0.7071, 1.406, 1.3219, 1.3219, 1.3219, 1.3219, 1.3219, 1.3218, 1.3218, 1.3218, 1.3218, 1.3217, 1.3213, 1.1761, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 1.1314, 0.9944, 0.9797, 0.976, 0.9765, 0.9724, 1.034, 1.0305, 1.0304, 1.0255, 1.024, 0.6985, 0.8049, 0.7995, 0.5738, 0.7936, 0.5673, 0.163, 0.4601, 0.2014, -0.2009, -0.1192, 0.4492, 0.0358, -0.2054, -0.1015, 0.6097, -0.2572, 0.7796, 0.5953, -0.1894]}, \"token.table\": {\"Topic\": [3, 1, 2, 3, 4, 3, 2, 3, 4, 1, 2, 1, 2, 3, 3, 2, 2, 4, 1, 3, 1, 1, 4, 3, 2, 2, 1, 1, 4, 1, 4, 3, 4, 3, 4, 1, 2, 1, 4, 3, 1, 3, 3, 3, 4, 3, 2, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 4, 3, 3, 3, 1, 3, 1, 1, 2, 3, 3, 2, 3, 1, 4, 1, 2, 4, 1, 3, 4, 1, 2, 3, 2, 2, 1, 2, 3, 2, 1, 2, 3, 4, 1, 2, 1, 3, 4, 3, 1, 2, 1, 1, 2, 3, 4, 1, 2, 3, 4, 1, 2, 3, 3, 1, 3, 4, 4, 2, 3, 3, 1, 4, 1, 2, 3, 4, 3, 1, 1, 3, 4, 4, 2, 2, 1, 2, 3, 4, 1, 3, 1, 1, 2, 3, 4, 1, 4, 3, 4, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 3, 4, 2, 3, 1, 2, 4, 1, 2, 4, 1, 2, 3, 4, 2, 3, 1, 4, 4, 1, 2, 1, 4, 1, 2, 3, 1, 2, 3, 4, 1, 3, 4, 1, 2, 3, 4, 3, 4, 1, 2, 3, 2, 3, 1, 2, 4, 4, 2, 3, 4, 3, 4, 4, 2, 3, 2, 4, 2, 3, 2, 4, 4, 1, 2, 4, 1, 2, 2, 1, 4, 4, 2, 3, 3, 1, 2, 4, 1, 2, 4, 4, 1, 3, 2, 3, 4, 2, 3, 1, 2, 4, 3, 4, 1, 2, 4, 1, 3, 2, 1, 3, 1, 2, 3, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 3, 4, 1, 3, 4, 3, 4, 3, 4, 4, 2, 4, 4, 2, 3, 4, 1, 3, 2, 2, 4, 4, 4, 1, 3, 4, 4, 2, 4, 2, 2, 1, 2, 1, 2, 3, 4, 1, 3, 4, 2, 1, 1, 2, 3, 4, 2], \"Freq\": [0.7349020454954592, 0.4416711706760805, 0.3312533780070604, 0.11041779266902013, 0.11041779266902013, 0.7349020079764574, 0.7243154589910655, 0.3748431129848225, 0.3748431129848225, 0.4074806204437771, 0.6112209306656656, 0.12088247641602821, 0.48352990566411286, 0.36264742924808463, 0.982659665030941, 0.9638191296410195, 0.722140641210823, 0.7464255651785867, 0.3627677922371111, 0.7255355844742222, 0.9386893325213691, 0.4888947284003815, 0.4888947284003815, 0.7349020269014248, 0.7243154696968043, 0.9638182459272314, 0.9386849049486504, 0.9386846653096902, 0.7464254561818452, 0.48898693058073067, 0.48898693058073067, 0.7349020475008926, 0.5016868599184602, 0.743798793495115, 0.3718993967475575, 0.930797461392868, 0.7243155828740798, 0.7092335823190336, 0.2364111941063445, 0.9826585072438727, 0.7010483285560659, 0.7349027668575109, 0.9826586800230669, 0.7438208469387344, 0.3719104234693672, 0.7349027681909638, 0.5842654301193085, 0.29213271505965427, 0.32607801399725056, 0.16303900699862528, 0.32607801399725056, 0.32607801399725056, 0.16917786627812983, 0.22557048837083976, 0.33835573255625967, 0.22557048837083976, 0.5703722010333659, 0.28518610051668297, 0.7464255387010853, 0.9826598274859806, 0.7349020444814346, 0.9826579141663074, 0.9386920335565753, 0.9826610844554224, 0.7010443785588205, 0.208325208389982, 0.208325208389982, 0.624975625169946, 0.7349020898090641, 0.36636061008583, 0.73272122017166, 0.7036047084451987, 0.5016870880228251, 0.1627281445874052, 0.4881844337622156, 0.3254562891748104, 0.291390482743692, 0.582780965487384, 0.5016869334201188, 0.35841213290593155, 0.23894142193728768, 0.35841213290593155, 0.7243154960497424, 0.7221396595991586, 0.331570380359282, 0.44209384047904265, 0.22104692023952133, 0.7221403204226686, 0.08679368757718055, 0.26038106273154166, 0.4339684378859027, 0.26038106273154166, 0.7026671004093574, 0.23422236680311914, 0.2951219398412593, 0.2951219398412593, 0.2951219398412593, 0.7380447846896251, 0.7026499084178327, 0.23421663613927754, 0.938687067981772, 0.4806512096623059, 0.12016280241557648, 0.24032560483115295, 0.12016280241557648, 0.705651204421227, 0.17641280110530674, 0.08820640055265337, 0.08820640055265337, 0.6304417540903239, 0.15761043852258097, 0.15761043852258097, 0.7349026561100749, 0.29138898245666006, 0.5827779649133201, 0.7464255334200971, 0.5016869184928061, 0.3663227601719828, 0.7326455203439656, 0.982655955783433, 0.9386863910948857, 0.5016868769738956, 0.4305085507978017, 0.2870057005318678, 0.21525427539890085, 0.07175142513296695, 0.7349027571950655, 0.9386865747198309, 0.2931885673038626, 0.5863771346077252, 0.2931885673038626, 0.5016870121847481, 0.8660515597662568, 0.9638197449387386, 0.4529240041700079, 0.3019493361133386, 0.1509746680566693, 0.1509746680566693, 0.7010472084292725, 0.7349026962422708, 0.9386886973254351, 0.7099715934059815, 0.1419943186811963, 0.1419943186811963, 0.1419943186811963, 0.9386890201209753, 0.501686889558045, 0.7428931677934875, 0.24763105593116247, 0.41207738310050146, 0.20603869155025073, 0.30905803732537607, 0.10301934577512536, 0.2917029341665205, 0.14585146708326024, 0.2917029341665205, 0.2917029341665205, 0.24354450315399304, 0.7306335094619791, 0.7437743186160369, 0.37188715930801847, 0.8035875158507197, 0.16071750317014397, 0.4840436360522193, 0.24202181802610964, 0.24202181802610964, 0.28640239532773093, 0.5728047906554619, 0.7464255422029388, 0.2400323932729637, 0.4800647865459274, 0.2400323932729637, 0.7464255387010853, 0.7273722499085304, 0.3636861249542652, 0.36852343837965185, 0.36852343837965185, 0.7556201899416644, 0.7010430387338282, 0.7221090285659054, 0.6144078249715993, 0.20480260832386643, 0.31819766991257015, 0.31819766991257015, 0.31819766991257015, 0.321321191957764, 0.160660595978882, 0.321321191957764, 0.160660595978882, 0.938688709351083, 0.5945467604322219, 0.29727338021611094, 0.24486330656572514, 0.24486330656572514, 0.24486330656572514, 0.24486330656572514, 0.7349019954112385, 0.5016868908252566, 0.7430543761164584, 0.16512319469254633, 0.08256159734627316, 0.7273719063942872, 0.3636859531971436, 0.9386868789026692, 0.29932616039138626, 0.5986523207827725, 0.7464255602506219, 0.49050648416732734, 0.49050648416732734, 0.24525324208366367, 0.5983786601456685, 0.29918933007283427, 0.7464254987548434, 0.5466779788230114, 0.3644519858820076, 0.9638170209422444, 0.746425510714722, 0.7243155277636745, 0.7349027599337209, 0.5913470460825446, 0.2956735230412723, 0.7464255040611031, 0.4332967436100467, 0.28886449574003115, 0.28886449574003115, 0.565330000609331, 0.42399750045699824, 0.48261322605974927, 0.5818519748619212, 0.2909259874309606, 0.746425492720521, 0.7273672629132437, 0.36368363145662186, 0.7349026580843503, 0.16055108141484034, 0.6422043256593614, 0.16055108141484034, 0.7460385342498705, 0.07853037202630216, 0.1570607440526043, 0.746425550660965, 0.4814497246626319, 0.4814497246626319, 0.963821132828311, 0.7349020552015474, 0.7464255046309178, 0.7221400340396255, 0.9826583487066538, 0.24609420037043694, 0.24609420037043694, 0.4921884007408739, 0.37486503894244066, 0.37486503894244066, 0.3217679329781321, 0.48265189946719816, 0.16088396648906605, 0.3626899563900398, 0.7253799127800796, 0.7243154928841985, 0.5669988999603985, 0.28349944998019927, 0.5116602023172655, 0.15349806069517966, 0.15349806069517966, 0.15349806069517966, 0.28514375496063776, 0.641573448661435, 0.07128593874015944, 0.357453004761053, 0.5004342066654742, 0.1429812019044212, 0.7010429455169261, 0.3714405504903014, 0.3714405504903014, 0.3714405504903014, 0.47544779287575223, 0.3169651952505015, 0.15848259762525074, 0.039620649406312686, 0.9386885483344082, 0.37484152333455356, 0.37484152333455356, 0.5005129461709262, 0.5005129461709262, 0.7437974173892704, 0.3718987086946352, 0.5016868900761579, 0.3720812133818502, 0.3720812133818502, 0.7464254663907961, 0.9638308510260508, 0.7438221431406067, 0.37191107157030334, 0.7010487523954572, 0.9826594764427596, 0.7243156001585916, 0.9638194217941494, 0.5016681348900434, 0.5016855054774727, 0.746425550660965, 0.2459712277281652, 0.2459712277281652, 0.4919424554563304, 0.7464254530048082, 0.7243154950381606, 0.7464255651785867, 0.9638170222495568, 0.7243154691672649, 0.7035618522228049, 0.35178092611140244, 0.14512808907363198, 0.5805123562945279, 0.14512808907363198, 0.14512808907363198, 0.36335026641088514, 0.4541878330136064, 0.09083756660272128, 0.9638193031495034, 0.9386884217000778, 0.5720634359980794, 0.1906878119993598, 0.0953439059996799, 0.1906878119993598, 0.724315599761695], \"Term\": [\"12day\", \"able\", \"able\", \"able\", \"able\", \"access\", \"addict\", \"answer\", \"answer\", \"anxiety\", \"anxiety\", \"appointment\", \"appointment\", \"appointment\", \"approach\", \"appt\", \"aspect\", \"assumption\", \"awful\", \"awful\", \"awkward\", \"bad\", \"bad\", \"billing\", \"binge\", \"briley\", \"care\", \"cautious\", \"chart\", \"chat\", \"chat\", \"checking\", \"christian\", \"chronic\", \"chronic\", \"client\", \"color\", \"comfortable\", \"comfortable\", \"company\", \"complicated\", \"computer\", \"concern\", \"contact\", \"contact\", \"convenient\", \"conversation\", \"conversation\", \"counseling\", \"counseling\", \"counseling\", \"counseling\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"couple\", \"couple\", \"covid\", \"dear\", \"department\", \"different\", \"difficult\", \"difficulty\", \"disorder\", \"email\", \"email\", \"email\", \"emailing\", \"emotion\", \"emotion\", \"emotional\", \"empathetic\", \"experience\", \"experience\", \"experience\", \"feel\", \"feel\", \"feeling\", \"first\", \"first\", \"first\", \"fluke\", \"food\", \"friend\", \"friend\", \"friend\", \"goal\", \"good\", \"good\", \"good\", \"good\", \"great\", \"great\", \"guidance\", \"guidance\", \"guidance\", \"happy\", \"hard\", \"hard\", \"hassert\", \"health\", \"health\", \"health\", \"health\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"helpful\", \"helpful\", \"helping\", \"hope\", \"hope\", \"hospital\", \"humor\", \"illness\", \"illness\", \"important\", \"intense\", \"interested\", \"issue\", \"issue\", \"issue\", \"issue\", \"jenning\", \"judgmental\", \"kind\", \"kind\", \"kind\", \"knowledgeable\", \"last\", \"less\", \"life\", \"life\", \"life\", \"life\", \"live\", \"love\", \"manner\", \"many\", \"many\", \"many\", \"many\", \"mean\", \"mechanism\", \"meeting\", \"meeting\", \"mental\", \"mental\", \"mental\", \"mental\", \"message\", \"message\", \"message\", \"message\", \"mind\", \"mind\", \"minute\", \"minute\", \"month\", \"month\", \"much\", \"much\", \"much\", \"need\", \"need\", \"needless\", \"negative\", \"negative\", \"negative\", \"nervous\", \"online\", \"online\", \"other\", \"other\", \"pandemic\", \"party\", \"past\", \"patient\", \"patient\", \"people\", \"people\", \"people\", \"person\", \"person\", \"person\", \"person\", \"personality\", \"phone\", \"phone\", \"point\", \"point\", \"point\", \"point\", \"policy\", \"practical\", \"problem\", \"problem\", \"problem\", \"professional\", \"professional\", \"progress\", \"ptsd\", \"ptsd\", \"qualification\", \"question\", \"question\", \"question\", \"questionnaire\", \"questionnaire\", \"racing\", \"reason\", \"reason\", \"recording\", \"regonize\", \"rematch\", \"remedy\", \"reply\", \"reply\", \"requirement\", \"response\", \"response\", \"response\", \"right\", \"right\", \"scared\", \"schedule\", \"schedule\", \"seat\", \"second\", \"second\", \"sense\", \"service\", \"service\", \"service\", \"session\", \"session\", \"session\", \"sign\", \"situation\", \"situation\", \"solution\", \"sorry\", \"specialty\", \"specific\", \"step\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"talk\", \"talk\", \"talk\", \"technique\", \"technique\", \"telling\", \"thank\", \"thank\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapy\", \"therapy\", \"therapy\", \"thing\", \"thing\", \"thing\", \"third\", \"thought\", \"thought\", \"thought\", \"time\", \"time\", \"time\", \"time\", \"timely\", \"today\", \"today\", \"tool\", \"tool\", \"tough\", \"tough\", \"toxic\", \"trauma\", \"trauma\", \"traumatized\", \"trigger\", \"type\", \"type\", \"unable\", \"unbelievable\", \"unheard\", \"unresponsive\", \"upset\", \"useful\", \"victim\", \"video\", \"video\", \"video\", \"violent\", \"visible\", \"vital\", \"voice\", \"website\", \"week\", \"week\", \"well\", \"well\", \"well\", \"well\", \"work\", \"work\", \"work\", \"worksheet\", \"wrong\", \"year\", \"year\", \"year\", \"year\", \"youper\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 3, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2261406699708044963264140478\", ldavis_el2261406699708044963264140478_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2261406699708044963264140478\", ldavis_el2261406699708044963264140478_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2261406699708044963264140478\", ldavis_el2261406699708044963264140478_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(doc_term_matrix,total_docs=10000))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=tokenized_reviews, dictionary=dictionary , coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0sLC3Yjjptm",
        "outputId": "6e4ce9a9-0ee1-4c0c-f30f-c394dd5bbb7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -5.73407070081014\n",
            "\n",
            "Coherence Score:  0.43675718003775704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, num_topics=num_topics, id2word=dictionary)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h0KuucG3jy-D",
        "outputId": "929e92e8-26fb-4fda-c9d9-6aba807a9338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_list, coherence_values = compute_coherence_values(dictionary=dictionary, corpus=doc_term_matrix, texts=tokenized_reviews, start=2, limit=50, step=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLv2pH3ej0Hh",
        "outputId": "9c7c9be1-7d6a-4d20-fd21-3e8c390a7d66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n",
            "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show graph\n",
        "limit=50; start=2; step=1;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()# Print the coherence scores\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "tHCpTZhWj4Ko",
        "outputId": "ea939f4e-803a-48ef-bc8b-51d8c53063fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the coherence scores\n",
        "for m, cv in zip(x, coherence_values):\n",
        "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcDnJKh8j7l1",
        "outputId": "c1e92c5e-52df-420b-c2a3-fcb1708940cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Topics = 2  has Coherence Value of 0.3061\n",
            "Num Topics = 3  has Coherence Value of 0.3544\n",
            "Num Topics = 4  has Coherence Value of 0.3504\n",
            "Num Topics = 5  has Coherence Value of 0.4117\n",
            "Num Topics = 6  has Coherence Value of 0.3927\n",
            "Num Topics = 7  has Coherence Value of 0.393\n",
            "Num Topics = 8  has Coherence Value of 0.3574\n",
            "Num Topics = 9  has Coherence Value of 0.3994\n",
            "Num Topics = 10  has Coherence Value of 0.4249\n",
            "Num Topics = 11  has Coherence Value of 0.4284\n",
            "Num Topics = 12  has Coherence Value of 0.4284\n",
            "Num Topics = 13  has Coherence Value of 0.432\n",
            "Num Topics = 14  has Coherence Value of 0.4186\n",
            "Num Topics = 15  has Coherence Value of 0.4387\n",
            "Num Topics = 16  has Coherence Value of 0.3995\n",
            "Num Topics = 17  has Coherence Value of 0.3875\n",
            "Num Topics = 18  has Coherence Value of 0.3849\n",
            "Num Topics = 19  has Coherence Value of 0.4167\n",
            "Num Topics = 20  has Coherence Value of 0.4011\n",
            "Num Topics = 21  has Coherence Value of 0.4023\n",
            "Num Topics = 22  has Coherence Value of 0.3742\n",
            "Num Topics = 23  has Coherence Value of 0.3995\n",
            "Num Topics = 24  has Coherence Value of 0.4106\n",
            "Num Topics = 25  has Coherence Value of 0.4192\n",
            "Num Topics = 26  has Coherence Value of 0.3858\n",
            "Num Topics = 27  has Coherence Value of 0.3921\n",
            "Num Topics = 28  has Coherence Value of 0.4013\n",
            "Num Topics = 29  has Coherence Value of 0.4101\n",
            "Num Topics = 30  has Coherence Value of 0.3748\n",
            "Num Topics = 31  has Coherence Value of 0.4157\n",
            "Num Topics = 32  has Coherence Value of 0.3819\n",
            "Num Topics = 33  has Coherence Value of 0.3894\n",
            "Num Topics = 34  has Coherence Value of 0.3791\n",
            "Num Topics = 35  has Coherence Value of 0.3891\n",
            "Num Topics = 36  has Coherence Value of 0.3624\n",
            "Num Topics = 37  has Coherence Value of 0.4006\n",
            "Num Topics = 38  has Coherence Value of 0.4126\n",
            "Num Topics = 39  has Coherence Value of 0.3881\n",
            "Num Topics = 40  has Coherence Value of 0.377\n",
            "Num Topics = 41  has Coherence Value of 0.4138\n",
            "Num Topics = 42  has Coherence Value of 0.3776\n",
            "Num Topics = 43  has Coherence Value of 0.3588\n",
            "Num Topics = 44  has Coherence Value of 0.3405\n",
            "Num Topics = 45  has Coherence Value of 0.3843\n",
            "Num Topics = 46  has Coherence Value of 0.3601\n",
            "Num Topics = 47  has Coherence Value of 0.3986\n",
            "Num Topics = 48  has Coherence Value of 0.3669\n",
            "Num Topics = 49  has Coherence Value of 0.3676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the model and print the topics\n",
        "optimal_model = model_list[11]\n",
        "model_topics = optimal_model.show_topics(formatted=False)\n",
        "optimal_model.print_topics(num_words=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkXrW8qej-ks",
        "outputId": "a4885cdd-5214-4f44-d414-bdb37f8ebbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0,\n",
              "  '0.032*\"time\" + 0.018*\"therapist\" + 0.017*\"work\" + 0.015*\"month\" + 0.013*\"issue\" + 0.011*\"talk\" + 0.011*\"session\" + 0.011*\"negative\" + 0.011*\"message\" + 0.011*\"therapy\"'),\n",
              " (1,\n",
              "  '0.019*\"helpful\" + 0.019*\"person\" + 0.019*\"patient\" + 0.019*\"session\" + 0.010*\"robin\" + 0.010*\"foxman\" + 0.010*\"hope\" + 0.010*\"suggestion\" + 0.010*\"real\" + 0.010*\"passion\"'),\n",
              " (2,\n",
              "  '0.024*\"therapist\" + 0.023*\"help\" + 0.023*\"right\" + 0.021*\"time\" + 0.020*\"session\" + 0.017*\"thing\" + 0.015*\"many\" + 0.013*\"issue\" + 0.011*\"expectation\" + 0.010*\"intense\"'),\n",
              " (3,\n",
              "  '0.035*\"month\" + 0.035*\"last\" + 0.012*\"ptsd\" + 0.012*\"pleasant\" + 0.012*\"problem\" + 0.012*\"timely\" + 0.012*\"mental\" + 0.012*\"personal\" + 0.012*\"party\" + 0.012*\"complicated\"'),\n",
              " (4,\n",
              "  '0.042*\"life\" + 0.023*\"counselor\" + 0.022*\"therapist\" + 0.016*\"well\" + 0.013*\"client\" + 0.012*\"friend\" + 0.011*\"relationship\" + 0.011*\"step\" + 0.011*\"appointment\" + 0.011*\"experience\"'),\n",
              " (5,\n",
              "  '0.029*\"reason\" + 0.025*\"counselor\" + 0.022*\"first\" + 0.018*\"session\" + 0.015*\"second\" + 0.015*\"happy\" + 0.014*\"health\" + 0.014*\"mental\" + 0.013*\"thought\" + 0.013*\"counseling\"'),\n",
              " (6,\n",
              "  '0.036*\"time\" + 0.024*\"good\" + 0.018*\"counselor\" + 0.018*\"session\" + 0.012*\"experience\" + 0.012*\"response\" + 0.012*\"contact\" + 0.012*\"long\" + 0.012*\"chat\" + 0.012*\"today\"'),\n",
              " (7,\n",
              "  '0.048*\"thing\" + 0.020*\"appt\" + 0.020*\"life\" + 0.020*\"scared\" + 0.020*\"specific\" + 0.020*\"session\" + 0.020*\"conversation\" + 0.020*\"reason\" + 0.020*\"time\" + 0.020*\"need\"'),\n",
              " (8,\n",
              "  '0.015*\"session\" + 0.014*\"therapist\" + 0.014*\"work\" + 0.012*\"constant\" + 0.012*\"survey\" + 0.012*\"responsive\" + 0.012*\"client\" + 0.012*\"time\" + 0.012*\"worried\" + 0.012*\"crap\"'),\n",
              " (9,\n",
              "  '0.021*\"time\" + 0.020*\"therapist\" + 0.018*\"mental\" + 0.016*\"issue\" + 0.016*\"bad\" + 0.016*\"therapy\" + 0.015*\"session\" + 0.013*\"health\" + 0.012*\"good\" + 0.012*\"phone\"'),\n",
              " (10,\n",
              "  '0.032*\"counselor\" + 0.023*\"year\" + 0.021*\"problem\" + 0.019*\"time\" + 0.017*\"service\" + 0.016*\"help\" + 0.014*\"counseling\" + 0.014*\"good\" + 0.012*\"able\" + 0.012*\"questionnaire\"'),\n",
              " (11,\n",
              "  '0.024*\"good\" + 0.021*\"week\" + 0.020*\"anxiety\" + 0.020*\"briley\" + 0.014*\"time\" + 0.013*\"mental\" + 0.012*\"therapist\" + 0.010*\"uncomfortable\" + 0.010*\"conversation\" + 0.010*\"thing\"'),\n",
              " (12,\n",
              "  '0.060*\"session\" + 0.028*\"therapy\" + 0.017*\"issue\" + 0.017*\"problem\" + 0.015*\"work\" + 0.013*\"thing\" + 0.012*\"counselor\" + 0.012*\"appointment\" + 0.012*\"day\" + 0.011*\"doctor\"')]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim.prepare(optimal_model, doc_term_matrix, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "p5nerhM0kBpE",
        "outputId": "860a7dca-9739-450e-a451-80c49661cb54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0     -0.044507  0.031511       1        1  17.232081\n",
              "10     0.061762  0.146789       2        1  12.755099\n",
              "2      0.071293 -0.088687       3        1  11.753555\n",
              "9     -0.078541 -0.002925       4        1   9.404019\n",
              "4      0.071673  0.049498       5        1   8.618780\n",
              "12     0.029654 -0.056876       6        1   8.593594\n",
              "6     -0.136131  0.014324       7        1   8.294273\n",
              "5      0.065149 -0.024363       8        1   6.311803\n",
              "1      0.001229 -0.087351       9        1   4.352558\n",
              "7      0.024503 -0.014351      10        1   3.891979\n",
              "11    -0.061042 -0.007641      11        1   3.347124\n",
              "3      0.002547  0.039694      12        1   2.925760\n",
              "8     -0.007587  0.000377      13        1   2.519376, topic_info=          Term       Freq      Total Category  logprob  loglift\n",
              "124      month   6.000000   6.000000  Default  30.0000  30.0000\n",
              "34       thing  13.000000  13.000000  Default  29.0000  29.0000\n",
              "85        life  12.000000  12.000000  Default  28.0000  28.0000\n",
              "55     session  24.000000  24.000000  Default  27.0000  27.0000\n",
              "168     reason   5.000000   5.000000  Default  26.0000  26.0000\n",
              "..         ...        ...        ...      ...      ...      ...\n",
              "51        help   0.442625  11.352700  Topic13  -4.4007   0.4367\n",
              "46     problem   0.442570  11.909266  Topic13  -4.4008   0.3887\n",
              "17   therapist   0.522415  19.829026  Topic13  -4.2350   0.0447\n",
              "55     session   0.532626  24.730819  Topic13  -4.2156  -0.1568\n",
              "65        time   0.442655  26.617029  Topic13  -4.4006  -0.4154\n",
              "\n",
              "[665 rows x 6 columns], token_table=      Topic      Freq   Term\n",
              "term                        \n",
              "334       1  0.643088  30min\n",
              "0         1  0.223109   able\n",
              "0         2  0.223109   able\n",
              "0         3  0.111554   able\n",
              "0         5  0.111554   able\n",
              "...     ...       ...    ...\n",
              "222       3  0.177884   year\n",
              "222       4  0.088942   year\n",
              "222       5  0.088942   year\n",
              "222       7  0.088942   year\n",
              "222      10  0.088942   year\n",
              "\n",
              "[815 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 11, 3, 10, 5, 13, 7, 6, 2, 8, 12, 4, 9])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2261406699408689122736795683\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2261406699408689122736795683_data = {\"mdsDat\": {\"x\": [-0.044507365694552686, 0.06176238046761833, 0.07129336467731279, -0.07854120179632704, 0.07167257034712633, 0.029653659324339186, -0.1361313485583434, 0.06514869333481023, 0.001229081996669319, 0.0245030632962536, -0.061042166571645795, 0.002546675959027187, -0.007587406782288315], \"y\": [0.03151100586007621, 0.14678939452184012, -0.08868746651334898, -0.0029249993138684804, 0.04949848499591926, -0.05687634261590379, 0.014324330595074422, -0.02436270891938016, -0.08735071694822635, -0.014351473608338687, -0.007640529376999135, 0.039693619466440296, 0.0003774018567152051], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.232081150542246, 12.755099035554926, 11.753554553408813, 9.404019269091632, 8.618780335656917, 8.593593752583327, 8.294272860203929, 6.3118027007993325, 4.352557500714345, 3.8919785753869203, 3.3471239913114195, 2.9257603363424276, 2.519375938403765]}, \"tinfo\": {\"Term\": [\"month\", \"thing\", \"life\", \"session\", \"reason\", \"good\", \"counselor\", \"help\", \"week\", \"last\", \"mental\", \"therapist\", \"problem\", \"time\", \"anxiety\", \"helpful\", \"counseling\", \"able\", \"first\", \"health\", \"patient\", \"experience\", \"conversation\", \"work\", \"friend\", \"need\", \"person\", \"email\", \"comfortable\", \"right\", \"hassert\", \"toxic\", \"short\", \"apprehensive\", \"mood\", \"mistake\", \"unrelated\", \"success\", \"general\", \"sentence\", \"wendy\", \"impact\", \"focus\", \"judgement\", \"multiple\", \"weird\", \"psychiatrist\", \"managementcommunication\", \"outlook\", \"wanted\", \"positive\", \"section\", \"swing\", \"audience\", \"incomplete\", \"anger\", \"straight\", \"dynamic\", \"30min\", \"browning\", \"negative\", \"month\", \"goal\", \"past\", \"video\", \"trauma\", \"week\", \"time\", \"work\", \"talk\", \"couple\", \"comfortable\", \"message\", \"available\", \"helpful\", \"depression\", \"therapist\", \"food\", \"friend\", \"question\", \"minute\", \"issue\", \"point\", \"appointment\", \"therapy\", \"able\", \"well\", \"many\", \"session\", \"good\", \"year\", \"problem\", \"life\", \"understanding\", \"mean\", \"lengthy\", \"interested\", \"online\", \"style\", \"trust\", \"balance\", \"love\", \"feedback\", \"quality\", \"fill\", \"assertive\", \"close\", \"warm\", \"popup\", \"wreck\", \"blunt\", \"intelligent\", \"sense\", \"psychologist\", \"helping\", \"savili\", \"leave\", \"skeptical\", \"superpower\", \"accountable\", \"various\", \"dead\", \"tonight\", \"questionnaire\", \"christian\", \"service\", \"ptsd\", \"type\", \"year\", \"counseling\", \"counselor\", \"problem\", \"worksheet\", \"help\", \"meeting\", \"able\", \"good\", \"system\", \"professional\", \"time\", \"health\", \"mental\", \"food\", \"people\", \"schedule\", \"tool\", \"response\", \"therapy\", \"issue\", \"session\", \"intense\", \"open\", \"expectation\", \"left\", \"schizoaffective\", \"helmholdt\", \"direction\", \"darkness\", \"depressed\", \"counselling\", \"shape\", \"page\", \"lee\", \"energy\", \"drop\", \"simmon\", \"transition\", \"hesitant\", \"confidence\", \"night\", \"path\", \"light\", \"potential\", \"weekend\", \"sick\", \"diagnosis\", \"nonresponsive\", \"motivation\", \"unwilling\", \"necessary\", \"live\", \"disorder\", \"right\", \"unhelpful\", \"important\", \"help\", \"waste\", \"many\", \"therapist\", \"high\", \"thing\", \"time\", \"mind\", \"session\", \"person\", \"issue\", \"year\", \"life\", \"situation\", \"technique\", \"care\", \"horrible\", \"anxiety\", \"terrible\", \"fantastic\", \"betterhelp\", \"wonder\", \"doubtful\", \"understood\", \"offer\", \"unicorn\", \"computer\", \"cyndi\", \"discouraged\", \"level\", \"safe\", \"basic\", \"concerned\", \"flag\", \"skill\", \"remedy\", \"jenning\", \"absolute\", \"invalided\", \"unprofessional\", \"rule\", \"woman\", \"convenient\", \"amount\", \"sleep\", \"metric\", \"suffering\", \"tragedy\", \"unique\", \"individual\", \"bad\", \"party\", \"phone\", \"third\", \"mental\", \"health\", \"therapist\", \"time\", \"issue\", \"therapy\", \"message\", \"good\", \"first\", \"question\", \"session\", \"friend\", \"work\", \"situation\", \"year\", \"right\", \"problem\", \"mind\", \"tool\", \"kind\", \"step\", \"disappoint\", \"homework\", \"spot\", \"basis\", \"insightful\", \"nonjudgemental\", \"patch\", \"hear\", \"console\", \"parenting\", \"councilor\", \"previous\", \"position\", \"choice\", \"pitied\", \"daily\", \"divorce\", \"loss\", \"experiance\", \"priscilla\", \"pace\", \"unhappiness\", \"hour\", \"regard\", \"negativity\", \"beam\", \"pandemic\", \"option\", \"fault\", \"life\", \"relationship\", \"client\", \"stay\", \"well\", \"bad\", \"counselor\", \"therapist\", \"experience\", \"appointment\", \"friend\", \"number\", \"terrible\", \"tool\", \"health\", \"point\", \"day\", \"year\", \"work\", \"thing\", \"entire\", \"awful\", \"check\", \"side\", \"response\", \"judgmental\", \"brick\", \"wall\", \"judgemental\", \"listener\", \"actual\", \"word\", \"hollywood\", \"stress\", \"narcissism\", \"truth\", \"rude\", \"face\", \"haley\", \"verge\", \"mouth\", \"narcissist\", \"stereotypical\", \"advance\", \"deal\", \"satisfied\", \"talking\", \"hand\", \"resource\", \"eleanor\", \"clarity\", \"stretch\", \"abuse\", \"few\", \"shit\", \"doctor\", \"unable\", \"session\", \"therapy\", \"much\", \"day\", \"problem\", \"issue\", \"work\", \"helpful\", \"response\", \"appointment\", \"able\", \"friend\", \"thing\", \"help\", \"counselor\", \"therapist\", \"message\", \"life\", \"first\", \"people\", \"time\", \"good\", \"reply\", \"humor\", \"tip\", \"consistent\", \"min\", \"mark\", \"adjective\", \"heck\", \"clear\", \"opposite\", \"account\", \"insult\", \"slow\", \"vernacular\", \"chatting\", \"attention\", \"siouneh\", \"name\", \"modern\", \"reading\", \"material\", \"underlying\", \"immediate\", \"busy\", \"unfortunate\", \"definition\", \"testimonial\", \"wish\", \"brief\", \"pejorative\", \"understatement\", \"today\", \"contact\", \"long\", \"good\", \"time\", \"chat\", \"experience\", \"counselor\", \"response\", \"session\", \"therapy\", \"present\", \"email\", \"full\", \"unbelievable\", \"counsellor\", \"waste\", \"enough\", \"hope\", \"address\", \"wrong\", \"mother\", \"formulaic\", \"father\", \"suicide\", \"worldview\", \"valid\", \"edlyne\", \"recommendation\", \"follow\", \"unhappy\", \"terminology\", \"medical\", \"informed\", \"reaffirmation\", \"distant\", \"understandable\", \"final\", \"reason\", \"happy\", \"different\", \"second\", \"clam\", \"setting\", \"professionalism\", \"breathing\", \"self\", \"current\", \"true\", \"meditation\", \"lack\", \"technique\", \"first\", \"share\", \"show\", \"counselor\", \"thought\", \"patient\", \"counseling\", \"health\", \"mental\", \"session\", \"issue\", \"response\", \"chronic\", \"aspect\", \"relationship\", \"addiction\", \"appointment\", \"grateful\", \"robin\", \"foxman\", \"suggestion\", \"passion\", \"kick\", \"weirdo\", \"interest\", \"excellent\", \"hole\", \"grandparent\", \"content\", \"honest\", \"input\", \"compassion\", \"husband\", \"butt\", \"less\", \"share\", \"awkward\", \"complete\", \"mechanism\", \"real\", \"story\", \"patient\", \"hour\", \"other\", \"tough\", \"check\", \"emotion\", \"kind\", \"helpful\", \"person\", \"session\", \"hope\", \"work\", \"chat\", \"people\", \"thought\", \"relationship\", \"first\", \"couple\", \"appointment\", \"life\", \"many\", \"high\", \"thing\", \"appt\", \"scared\", \"lovely\", \"push\", \"lose\", \"assessment\", \"observation\", \"compatible\", \"reach\", \"astute\", \"specific\", \"case\", \"conversation\", \"need\", \"detail\", \"single\", \"wrong\", \"priority\", \"complicated\", \"last\", \"money\", \"reason\", \"thing\", \"short\", \"change\", \"rough\", \"hard\", \"email\", \"people\", \"service\", \"life\", \"therapist\", \"session\", \"time\", \"first\", \"health\", \"friend\", \"able\", \"year\", \"briley\", \"uncomfortable\", \"counterproductive\", \"drone\", \"productive\", \"brittany\", \"damn\", \"way\", \"ssris\", \"oneway\", \"endless\", \"water\", \"lot\", \"saddens\", \"less\", \"technical\", \"panic\", \"difficulty\", \"place\", \"respond\", \"responsive\", \"anxiety\", \"attack\", \"illness\", \"week\", \"conversation\", \"kind\", \"long\", \"great\", \"12day\", \"good\", \"mental\", \"time\", \"therapist\", \"thing\", \"talk\", \"session\", \"last\", \"pleasant\", \"lifesaver\", \"responsiveness\", \"leslie\", \"diggity\", \"bomb\", \"approach\", \"stressful\", \"timely\", \"manner\", \"trigger\", \"month\", \"complicated\", \"third\", \"party\", \"text\", \"personal\", \"family\", \"thank\", \"ptsd\", \"comfortable\", \"depression\", \"anxiety\", \"experience\", \"health\", \"able\", \"friend\", \"mental\", \"help\", \"problem\", \"issue\", \"counselor\", \"thing\", \"constant\", \"worried\", \"crap\", \"redundant\", \"clinical\", \"plan\", \"confusing\", \"technic\", \"case\", \"action\", \"annoying\", \"responsive\", \"text\", \"sure\", \"online\", \"survey\", \"feel\", \"heavy\", \"dismissive\", \"client\", \"much\", \"support\", \"cuss\", \"thinking\", \"advice\", \"third\", \"email\", \"mutual\", \"stuff\", \"privacy\", \"toxic\", \"counseling\", \"well\", \"work\", \"able\", \"help\", \"problem\", \"therapist\", \"session\", \"time\"], \"Freq\": [6.0, 13.0, 12.0, 24.0, 5.0, 11.0, 18.0, 11.0, 5.0, 2.0, 9.0, 19.0, 11.0, 26.0, 4.0, 6.0, 6.0, 8.0, 8.0, 8.0, 4.0, 5.0, 3.0, 11.0, 9.0, 3.0, 6.0, 4.0, 4.0, 7.0, 1.8960759446620588, 1.5241062670350713, 1.8960731868661205, 0.9831881499115891, 0.9831874604626045, 0.9831676962583801, 0.9831639042889649, 0.9831613763093549, 0.9831599974113857, 0.9831560905338064, 0.9831562054419705, 0.9831551712684936, 0.9831550563603295, 0.9831547116358372, 0.9831545967276731, 0.9831527581970476, 0.9831526432888835, 0.9831478171459915, 0.9831463233398583, 0.9831449444418892, 0.9831429910030995, 0.9831408077479816, 0.983140003390833, 0.9831379350438793, 0.9831358666969255, 0.9831298914723926, 0.9831311554621976, 0.9831309256458695, 0.9831258696866493, 0.9831248355131724, 2.808962705239052, 3.7219636845311554, 1.8960927212540168, 1.8959991860084429, 2.6653196863642137, 1.7019998474737632, 2.6926331271534436, 7.8945659336251826, 4.141088455274441, 2.808975115320774, 1.7681338624210994, 1.8960488263353321, 2.808960636892098, 1.2454943018684912, 2.4784928005242266, 1.8960433107434556, 4.526919274919971, 1.4761257885760732, 2.5887067363003307, 1.7438527331741918, 1.408102568502839, 3.126418111288393, 1.6718228952352674, 2.2365283812245376, 2.808954891483893, 2.1130177323319304, 1.8960570997231472, 1.896077553376356, 2.808969140096241, 2.1545908166527856, 1.8959590830591735, 1.8959797665287106, 1.8960024034370375, 1.5966717175413183, 1.5453895037884287, 1.4183251448282617, 1.4110175225030868, 1.5967065898617359, 0.8279547066445951, 0.8279484976704721, 0.8279450954928703, 0.827936590048866, 0.827934633796745, 0.8279274892237815, 0.8279247674817001, 0.8279188987253371, 0.8279196642152975, 0.8279194941064174, 0.8279182182898167, 0.8279181332353767, 0.8279145609488949, 0.8279184734531368, 0.8279132851322942, 0.827910818553533, 0.8279091174647322, 0.82790494979717, 0.8279021430006486, 0.8279031636539291, 0.8278966995164858, 0.8278921916311636, 0.8278939777744044, 0.8278921065767235, 0.8278894698890822, 2.2144076563188615, 1.2304868368241657, 3.1342676829886065, 1.7432070791338903, 1.4704650475545449, 4.171235765975964, 2.598292876335604, 5.760988985255304, 3.85821025050345, 1.1416366722853608, 2.907833371181795, 1.5967162860679007, 2.2725714547067506, 2.534772519422686, 1.3732712976108412, 1.204469874377171, 3.3951922506683765, 1.8162788795547573, 1.9370146778490844, 1.1815691365044718, 1.539892435328449, 1.178092961539914, 1.21854944616413, 1.3192800148881418, 1.5966678050370764, 1.5102523238445025, 1.4899605458656824, 1.6741844798592778, 1.4981060310452046, 1.8888183710660915, 0.8681037695774189, 0.8680988318975239, 0.8680967157489974, 0.8680967941248687, 0.8680881727790204, 0.8680872322685642, 0.8680872322685642, 0.8680862133822367, 0.8680866052615934, 0.8680837837302249, 0.8680827648438973, 0.8680822162127978, 0.8680811189505989, 0.8680802568160141, 0.8680790028020725, 0.8680741434980489, 0.868069440945768, 0.868067873428341, 0.8680677166765983, 0.8680681085559551, 0.8680605844723055, 0.8680596439618493, 0.8680600358412061, 0.8680587818272645, 0.8680503172331587, 0.8680534522680128, 0.8680473389500475, 1.6741825988383654, 1.674127735728421, 3.8750855385257728, 1.6741565780490775, 1.2663721706033253, 3.8958118809522877, 1.4261003937676582, 2.4801430021577033, 4.092458196181008, 1.4522133530802508, 2.8902165336779473, 3.5720264217455284, 1.4885469962719884, 3.286262351744137, 1.6741200548930288, 2.225368594935986, 1.6741283627353918, 1.6741499944758842, 1.0763943096365969, 0.8681186609929752, 0.8681083153779571, 0.868108080250343, 0.868101104797793, 0.8680999291597228, 0.8680985183940384, 1.4516884472178055, 1.2870979786228163, 0.752725241104584, 0.752717402537525, 0.7527159602411861, 0.752712887522899, 0.7527112571009507, 0.7527049862473034, 0.7526968341375619, 0.7526968341375619, 0.7526945766302489, 0.7526955799668325, 0.752695391841223, 0.7526931343339099, 0.7526923191229359, 0.7526867380631898, 0.7526829755510014, 0.7526832263851473, 0.7526822230485637, 0.7526782097022294, 0.7526760776119894, 0.7526741336473587, 0.752670057592488, 0.7526611529803088, 0.7526542550412968, 0.7526479841876496, 0.7454710548968655, 0.7454033296774748, 0.7450563633451703, 0.7440441848579618, 2.150588756668945, 1.252273294560897, 1.6317412104850577, 1.1006656251060327, 2.4517640614701377, 1.8018328481506665, 2.7138511288146208, 2.872474880164216, 2.1858655692788336, 2.150463339595999, 1.5076666018881195, 1.635157320717954, 1.4119785173305037, 1.138033140321927, 1.997558355938584, 1.4302277047806937, 1.1605782387717278, 0.8994511137035716, 0.8548119165982828, 0.8305193193625924, 0.7932668743111259, 0.752724300476537, 0.7527161483667956, 0.7527121350204613, 1.4017931828435717, 0.7268696114604165, 0.7268642090593747, 0.7268624274164779, 0.7268592664371449, 0.726853174367885, 0.7268548410660788, 0.7268527145890729, 0.7268504156950125, 0.726850013388552, 0.7268480018562492, 0.7268462776857039, 0.7268450707663222, 0.7268409327570136, 0.7268398982546864, 0.7268366798030019, 0.7268346107983475, 0.7268298405931723, 0.7268280589502756, 0.7268249554432941, 0.7268233462174518, 0.7268140931688589, 0.7268075413207868, 1.4017605385479146, 0.6347872374557115, 0.6335381908403673, 0.622745975201664, 1.252384149740985, 0.6178371467145809, 0.6058703111557375, 5.170497344830421, 1.4018044474244673, 1.6162188480929927, 0.8682978039430633, 1.9406107313832153, 1.3133138080273146, 2.8705057924477364, 2.7516079112036307, 1.4017852516590634, 1.4017930678988686, 1.42245748177332, 0.9429291007185342, 0.933139087945444, 1.0230521105700918, 1.0683727379654009, 0.9124628347665817, 0.8925634928354175, 1.0407877334116469, 1.0400257649753413, 0.9068707749647602, 0.7391300732631193, 0.7385765570457365, 0.7268781173684399, 0.7268672550940046, 0.7268667953151926, 1.3942756627109625, 0.7229872161091385, 0.7229865857607322, 0.722977990100645, 0.7229766720994317, 0.7229752394894171, 0.7229721450517858, 0.722971285485777, 0.7229725461825899, 0.722969107918555, 0.7229673887865375, 0.7229657842633213, 0.7229651539149149, 0.7229650393061138, 0.722964466262108, 0.7229643516533067, 0.7229621740860847, 0.7229591942572545, 0.7229547818184098, 0.7229543806876056, 0.7229527761643895, 0.7229515727719772, 0.7229515154675766, 0.722951057032372, 0.7229463007671237, 0.7229426905898871, 0.722941086066671, 0.7229375904982355, 0.7229379343246389, 0.7229374185850337, 1.3942966361215752, 1.3942726828821324, 7.436296708866488, 3.408258533842026, 1.3942917079431252, 1.4290510674211105, 2.065561416005959, 2.0861724335893106, 1.810076737152693, 1.3942948023807566, 1.3942684423564893, 1.475503962881643, 1.3942473543370757, 1.3942201920512003, 1.5520954201749162, 1.39425468930035, 1.5113462609218071, 1.3942684423564893, 0.8773826345075767, 0.9087860763743402, 0.7523500482712147, 0.7480797243399228, 0.7598558932681079, 0.7440752355229259, 0.7229767294038323, 1.4038008681786287, 0.7666728767305837, 0.7666706643926576, 0.7666685073631797, 0.7666664056421499, 0.7666648570056016, 0.7666629212099163, 0.7666612066480235, 0.7666607088719902, 0.7666600451706124, 0.7666603217128531, 0.7666584412256159, 0.7666578328326863, 0.7666568372806195, 0.7666558970370009, 0.7666562288876898, 0.7666554545694156, 0.766654846176486, 0.7666541824751082, 0.7666527444554562, 0.7666487622471893, 0.7666477113866743, 0.7666464392923669, 0.7666445034966815, 0.7666436738699592, 0.7666395257363477, 0.7666397469701404, 0.7666388067265217, 0.7666384195673848, 0.7666358753787696, 1.478517272021692, 1.4785579790395322, 1.4785296611140781, 2.90234732038049, 4.326018412259297, 1.4785244621199518, 1.4785719167684668, 2.1904039229671888, 1.4785660540729626, 2.1903627734817634, 1.478482538316252, 0.7666743147502357, 0.7666710515517947, 0.7666691157561094, 0.7666659078661165, 0.7666646910802571, 0.7666641379957756, 0.7666638614535349, 0.7666636955281905, 0.7666619809662977, 0.7666619809662977, 0.7008343716421329, 0.7008327722676373, 0.7008307520051165, 0.7008286475649907, 0.7008278899665454, 0.7008266273024699, 0.700821492468563, 0.7008205665149077, 0.7008203560708951, 0.7008195142948448, 0.700818882962807, 0.7008185041635844, 0.7008102547582913, 0.7008106335575139, 0.7008047411251617, 0.7007991854032296, 0.7007809188629377, 2.6530967920420885, 1.3515493130707084, 0.9617315786392202, 1.3515658960588994, 0.5779925615998956, 0.5746811829731535, 0.5721306015406891, 0.5604685098731715, 0.5576107222711434, 0.5691146021300035, 0.5572861334261406, 0.5392831953043904, 0.5377706079195734, 0.9966561093684817, 2.0023453175329293, 0.7007967021638811, 0.7007738058553125, 2.2583260473305273, 1.2124073515901073, 1.0192969389058684, 1.1545625216747535, 1.2774307634849706, 1.2357237064078743, 1.6108884767762615, 1.1451528964514803, 0.8097723141284473, 0.7145928644741656, 0.7008364760822586, 0.7008340770205153, 0.7008304152946964, 0.700825406727197, 0.7008233864646762, 0.6246151757154071, 0.6246124474568531, 0.6246064685072559, 0.6246039143928648, 0.624603275864267, 0.6246013022304194, 0.6245987481160283, 0.624596658386072, 0.6245949169444417, 0.6245927111183768, 0.6245884155623554, 0.6245878931298663, 0.6245824946608125, 0.6245694338485855, 0.624561887601521, 0.6245629905145536, 0.6245687953199878, 0.6245912599170181, 0.6245750064618023, 0.6245797664022584, 0.6245549218349999, 0.6246057138825494, 0.6245330957665672, 1.2045173283242947, 0.6245824946608125, 0.6245691436083138, 0.6245907374845291, 0.6245952071847134, 0.6245825527088669, 0.6245762835189979, 1.2045720095914851, 1.2045706164381809, 1.2044876077204714, 0.6246096031021903, 0.6246033919603757, 0.6245991544524088, 0.6245968905782894, 0.6245967164341264, 0.6245967164341264, 0.6245959618094199, 0.6245956715691482, 0.6245939881755722, 0.6245924208781051, 0.624592246733942, 0.6245911438209095, 0.6245907955325835, 1.0872625487737753, 1.087239710342606, 0.5637641819511088, 0.5637490255376963, 0.5637474683719348, 0.5637467936001048, 0.5637409801812617, 0.5637335576911316, 0.563730910509337, 0.5637298204933039, 1.0872300559148844, 0.5637264985396793, 1.0872115775478473, 1.087154792903076, 0.563739942070754, 0.5637360491563501, 0.5637471569387825, 0.5637401496928556, 0.5637354781955709, 0.5637638186124311, 0.5636930713813314, 1.0871986011665011, 2.6575898905837305, 0.5637578494770118, 0.5637171036395846, 0.5637363605895025, 0.5637547351454887, 0.5637421740083456, 0.5637192836716508, 0.5637221903810723, 1.0872410598862658, 1.0871419203327806, 1.087223412007635, 1.0871808494768194, 0.5637529703576256, 0.5637475202774602, 0.5637419144807186, 0.5637413435199394, 0.5637400977873301, 0.9607299539512988, 0.49816787857239714, 0.498157745507868, 0.4981531476856367, 0.49815113892835117, 0.498150112230183, 0.4981518977922146, 0.49814524657364695, 0.4981437734849709, 0.49814314853825986, 0.49813877391128253, 0.4981284176514994, 0.4981216771548302, 0.498075743571568, 0.49815457613526193, 0.4981453358517485, 0.498150112230183, 0.49816078096332167, 0.49815439757905877, 0.49815323696373826, 0.49813779185216517, 0.9607365605308156, 0.4981554689162777, 0.4981602006556614, 1.0196780524711417, 0.49816747682094004, 0.4981295782668199, 0.49815618314109034, 0.4981283730124486, 0.16866981402278491, 1.144329566344878, 0.6192319304903986, 0.6762148394382924, 0.5527462157714225, 0.4981663608446703, 0.49814917481011645, 0.4981476570823896, 1.457152209436841, 0.5100298924179566, 0.5100231420413723, 0.5100148699035928, 0.5100120604983093, 0.5099854101676328, 0.5099788548886376, 0.5099941115201083, 0.5100126848105945, 0.5100282535982078, 0.5099985597451407, 0.5099365187117942, 1.457176713694037, 0.5100237273341398, 0.5100039834581188, 0.510025951446656, 0.5099299634327992, 0.5100263416418342, 0.5100053881607607, 0.5100164697038237, 0.5100301265350636, 0.5100149479426285, 0.5100057393364211, 0.5100100705029, 0.5100152210792533, 0.5100216592996949, 0.5100099144248287, 0.5100014862089779, 0.5100278243835117, 0.5099961405350354, 0.5100288779104931, 0.5100144406888968, 0.5099953601446788, 0.509992394661324, 0.4426571336228113, 0.4426542104440117, 0.4426521944586327, 0.44264396251833493, 0.4426434921217465, 0.44264322332369593, 0.44264204733222484, 0.4426417785341743, 0.442631900205817, 0.44264846488568144, 0.4426508168686237, 0.4426561592298781, 0.44264009854635844, 0.44264990967520307, 0.4426508840681363, 0.4426567976252481, 0.44264402971784755, 0.18598436154575954, 0.153038893283239, 0.44265562163377703, 0.4426312282106907, 0.4425721598390849, 0.15249482922907134, 0.1488143959214665, 0.14730736285124538, 0.23802989688477058, 0.4426373433663404, 0.13587811174205242, 0.1345880826980065, 0.1162898066065154, 0.19908349534410444, 0.4426293802240932, 0.4426285738299416, 0.5200797753139959, 0.4426261882472431, 0.4426248442569904, 0.4425698750556553, 0.5224149919778036, 0.5326259579226271, 0.4426553864354828], \"Total\": [6.0, 13.0, 12.0, 24.0, 5.0, 11.0, 18.0, 11.0, 5.0, 2.0, 9.0, 19.0, 11.0, 26.0, 4.0, 6.0, 6.0, 8.0, 8.0, 8.0, 4.0, 5.0, 3.0, 11.0, 9.0, 3.0, 6.0, 4.0, 4.0, 7.0, 2.4679494912975484, 2.2634405717940362, 2.9914325888226325, 1.5550598628594516, 1.5550593439443603, 1.5550395071902823, 1.5550358475737087, 1.5550336366511839, 1.5550318257945477, 1.5550283764774506, 1.5550286284651778, 1.555027041247566, 1.5550270141923628, 1.5550270493573237, 1.555026954014581, 1.5550247884471413, 1.5550250663567065, 1.5550198711334215, 1.5550182295586898, 1.5550172986729782, 1.5550149355295841, 1.5550127176424646, 1.5550121122148015, 1.5550100696903522, 1.5550097535206926, 1.5550021114280268, 1.5550042497991545, 1.5550047646472396, 1.554998000823168, 1.5549989295157167, 4.710806676892399, 6.426469529155723, 3.14286740428301, 3.1427951290392557, 4.748934822149488, 3.1095705045356823, 5.725942207644394, 26.61702904431985, 11.446956733370719, 6.694572125142334, 3.656114796505366, 4.161180775590374, 7.597758766215543, 2.2213843917339315, 6.506222977137952, 4.352288149750181, 19.829025849688175, 3.1704222307609182, 9.164863472239988, 4.4483757280195855, 3.000673028788286, 14.581282073279283, 4.531862689959269, 8.377683746819283, 14.450497716748753, 8.964245937659589, 7.17104117999721, 7.526449208077265, 24.73081907240881, 11.97597461008888, 11.243292267762412, 11.909266231047347, 12.914339112188117, 2.179633799934495, 2.175014791462913, 2.157328784176908, 2.1511796381075956, 2.5907014365363876, 1.4109150966144604, 1.4109092604541174, 1.410906100201104, 1.410897326009211, 1.4108954590412508, 1.410888030034697, 1.4108859815316412, 1.4108794789489327, 1.410880858751845, 1.4108806632212774, 1.4108787763842014, 1.4108806541514018, 1.4108751326057065, 1.4108819199542442, 1.4108741147297852, 1.4108727682502398, 1.4108699319524098, 1.4108668118060115, 1.4108627555871658, 1.4108668569300606, 1.4108597822024238, 1.4108528873999437, 1.4108560907769438, 1.410855200647052, 1.4108508693530197, 3.8381555703637447, 2.1234048331690323, 6.578447939943541, 3.3432902129773847, 2.915497219209381, 11.243292267762412, 6.174133643284181, 18.071637920912835, 11.909266231047347, 2.264980051961596, 11.352700467262776, 4.217143624175164, 8.964245937659589, 11.97597461008888, 3.6877411522509225, 2.9245396512278146, 26.61702904431985, 8.021962192693037, 9.413985095588899, 3.1704222307609182, 6.113380465666741, 3.5927607974194697, 4.418949616252749, 7.172126163096131, 14.450497716748753, 14.581282073279283, 24.73081907240881, 2.25427677743522, 2.24612064231532, 2.9852127975906835, 1.4481957124716665, 1.448190350354709, 1.4481882563762325, 1.4481887856149216, 1.4481797228544229, 1.448178824153489, 1.4481794031345925, 1.4481778182952152, 1.4481789921498254, 1.4481759384780934, 1.4481744107162657, 1.448174413343331, 1.4481734688242207, 1.448172285839298, 1.4481710384278887, 1.448165797007642, 1.4481615526949372, 1.4481595299006054, 1.448159413554993, 1.4481603386244635, 1.4481528207796301, 1.4481513510595778, 1.4481523819362827, 1.448152670119314, 1.448142077525645, 1.4481474411136606, 1.448139774787592, 2.9255905017540447, 2.925541519919472, 7.629420860632231, 3.042687963659941, 2.235402470088889, 11.352700467262776, 2.9258105712160036, 7.526449208077265, 19.829025849688175, 3.4488534219344142, 13.023209350337572, 26.61702904431985, 4.369662337611869, 24.73081907240881, 6.574089616600572, 14.581282073279283, 11.243292267762412, 12.914339112188117, 4.482598380061277, 2.7609401416918904, 2.2099871373809346, 2.2169129678249098, 4.4587318130514415, 2.858974662754543, 2.1230873354618947, 2.040024597036672, 1.9721734873840104, 1.341059341749382, 1.3410521949224183, 1.3410504431792893, 1.3410473743367022, 1.3410453227498613, 1.3410414008233744, 1.3410311212107577, 1.34103200652844, 1.3410289167980831, 1.3410307213381731, 1.3410321068336863, 1.3410282550276253, 1.3410270782214273, 1.3410209471874128, 1.34101722775844, 1.3410192452502312, 1.341017597990373, 1.3410136819802478, 1.3410132130206522, 1.3410097815064628, 1.341004416903754, 1.3409964314031018, 1.3409920690974304, 1.3409858533123007, 1.340821990482583, 1.3408134636381865, 1.3407982076492266, 1.3407575154129583, 4.101093774991003, 2.431452419100923, 3.340308649317749, 2.368978394658941, 9.413985095588899, 8.021962192693037, 19.829025849688175, 26.61702904431985, 14.581282073279283, 14.450497716748753, 7.597758766215543, 11.97597461008888, 8.10195640802569, 4.4483757280195855, 24.73081907240881, 9.164863472239988, 11.446956733370719, 4.482598380061277, 11.243292267762412, 7.629420860632231, 11.909266231047347, 4.369662337611869, 4.418949616252749, 3.189597888588007, 1.9919751881617984, 1.317050681333402, 1.3170453978606613, 1.317043423378746, 1.3170403819771561, 1.3170341319180991, 1.3170375269001566, 1.3170338249612277, 1.3170316871489958, 1.317031308846396, 1.317029531881351, 1.3170274778722773, 1.317026330075974, 1.3170220793697678, 1.3170212999075204, 1.3170179586634814, 1.3170158958891887, 1.3170115405412803, 1.3170098810600246, 1.3170073169063519, 1.3170046924994232, 1.3169957479831584, 1.3169907078466698, 2.571908365855955, 1.3165231462318903, 1.3165369322242273, 1.3315220189420551, 2.6840165157898794, 1.3322143529216215, 1.316390365760591, 12.914339112188117, 3.2227337108001883, 3.7744038622736515, 2.0630266158793384, 7.17104117999721, 4.101093774991003, 18.071637920912835, 19.829025849688175, 5.874860472854072, 8.377683746819283, 9.164863472239988, 2.849868213277103, 2.858974662754543, 4.418949616252749, 8.021962192693037, 4.531862689959269, 4.135947357713235, 11.243292267762412, 11.446956733370719, 13.023209350337572, 2.015473609434691, 2.7843099922478984, 2.703108175004428, 2.085824159866651, 7.172126163096131, 1.9847356030498826, 1.3134458013370611, 1.3134451773738318, 1.3134367113811984, 1.3134353508823287, 1.3134338862617265, 1.3134308583776386, 1.3134300043666316, 1.313432297880081, 1.3134287750318925, 1.3134261971636174, 1.313424611687661, 1.3134239783959878, 1.3134238670081289, 1.3134231991923, 1.3134232158642678, 1.3134219103352718, 1.3134180155406492, 1.3134136969842516, 1.3134143209995677, 1.313412176831849, 1.3134104141188454, 1.3134103492764717, 1.3134099261806387, 1.3134069700218576, 1.313401814289822, 1.3134021365184831, 1.313396619771959, 1.313398158463986, 1.3133985980672038, 2.683545772737455, 2.790751319238572, 24.73081907240881, 14.450497716748753, 3.9137172331025853, 4.135947357713235, 11.909266231047347, 14.581282073279283, 11.446956733370719, 6.506222977137952, 7.172126163096131, 8.377683746819283, 8.964245937659589, 9.164863472239988, 13.023209350337572, 11.352700467262776, 18.071637920912835, 19.829025849688175, 7.597758766215543, 12.914339112188117, 8.10195640802569, 6.113380465666741, 26.61702904431985, 11.97597461008888, 3.7746163202066096, 2.0616080883820724, 1.3540108019479378, 1.354008838254744, 1.354006696291242, 1.354004437502745, 1.3540027573182785, 1.354001485385265, 1.3539989814894209, 1.3539986433807656, 1.3539978248008975, 1.3539983143970715, 1.3539962097163998, 1.3539958467574327, 1.3539946001540248, 1.3539936843874993, 1.353994544530469, 1.3539934649067964, 1.3539928917024018, 1.3539928030683626, 1.3539914582462722, 1.3539868826554118, 1.3539858661598134, 1.3539846391529147, 1.3539825847479416, 1.3539817402435754, 1.3539777822182943, 1.3539786303011565, 1.3539769901975147, 1.3539765253928626, 1.3539744830862912, 2.7644233833500946, 2.8477376644610595, 3.297227103769741, 11.97597461008888, 26.61702904431985, 4.364791543637327, 5.874860472854072, 18.071637920912835, 7.172126163096131, 24.73081907240881, 14.450497716748753, 2.0289393115212135, 4.520345922285936, 2.0253239966549024, 2.052916149154729, 2.1201802610625187, 2.9258105712160036, 2.1213201505101447, 3.4386332892672167, 2.0253187073278287, 1.8774758025480582, 1.2928755192399857, 1.292874363229849, 1.292871857336632, 1.2928697214037481, 1.2928690147417568, 1.2928675109777812, 1.2928624199932268, 1.2928617464603602, 1.2928615963571377, 1.2928604309051275, 1.2928607706340567, 1.2928604086902304, 1.2928515710922457, 1.2928526236037658, 1.29284699041151, 1.2928414025684116, 1.292822251139386, 5.2049588121499895, 2.741082179323647, 1.9559484638122897, 2.7874490122922895, 1.296741444385261, 1.3229666048871151, 1.3235838511043037, 1.2973058463594136, 1.2973947771477625, 1.324279953671369, 1.3271238448902416, 1.2979034345558462, 1.3317580397213384, 2.7609401416918904, 8.10195640802569, 1.872816048291463, 1.9641189031003845, 18.071637920912835, 5.693379038172562, 4.57152500530121, 6.174133643284181, 8.021962192693037, 9.413985095588899, 24.73081907240881, 14.581282073279283, 7.172126163096131, 2.9541468219393354, 2.8807111462723234, 3.2227337108001883, 2.9842280589007437, 8.377683746819283, 2.098932945886012, 1.2221018788438152, 1.2220994554920257, 1.2220924076936044, 1.2220899248425126, 1.2220909113915206, 1.2220888808690173, 1.2220846920211696, 1.2220831631058218, 1.222082005059858, 1.2220793314397262, 1.2220744210756398, 1.2220759801228513, 1.2220698097522014, 1.2220556567205478, 1.2220487881129491, 1.2220517188979838, 1.684624614844059, 1.872816048291463, 1.9084022465674133, 1.9205962402860302, 1.9323232059913364, 1.9325430934847314, 1.9791136698595178, 4.57152500530121, 2.571908365855955, 2.618951053596629, 2.665796443964777, 2.703108175004428, 2.7178079150752903, 3.189597888588007, 6.506222977137952, 6.574089616600572, 24.73081907240881, 3.4386332892672167, 11.446956733370719, 4.364791543637327, 6.113380465666741, 5.693379038172562, 3.2227337108001883, 8.10195640802569, 3.656114796505366, 8.377683746819283, 12.914339112188117, 7.526449208077265, 3.4488534219344142, 13.023209350337572, 1.6890963078217747, 1.6890761133029706, 1.1655969142818305, 1.165582284679381, 1.1655812877752822, 1.1655819786373365, 1.1655748303652513, 1.1655666361985617, 1.1655644814152428, 1.1655638071772567, 2.601960445972934, 1.576572800842409, 3.064520112850982, 3.4079662572970424, 1.8368952366739757, 1.8404862878999768, 1.8774758025480582, 1.9493838410260376, 2.3510083938524406, 2.586324870797366, 2.605159545106203, 5.2049588121499895, 13.023209350337572, 2.9914325888226325, 3.6261996529784652, 3.877285273326699, 4.114262765761243, 4.520345922285936, 6.113380465666741, 6.578447939943541, 12.914339112188117, 19.829025849688175, 24.73081907240881, 26.61702904431985, 8.10195640802569, 8.021962192693037, 9.164863472239988, 8.964245937659589, 11.243292267762412, 1.5672490151018394, 1.104686693052792, 1.104676269594103, 1.1046721694370112, 1.1046697695440182, 1.1046691677962035, 1.1046731437499653, 1.1046639066636612, 1.1046624848215578, 1.1046622619059459, 1.104658045399309, 1.1046472846770152, 1.1046442004142507, 1.104610327103281, 1.684624614844059, 1.7759874814687417, 1.8036038402880838, 1.816523594941569, 1.8734494443720164, 1.910757104289437, 2.2875852733319197, 4.4587318130514415, 2.5526138916153696, 2.668335829530048, 5.725942207644394, 3.064520112850982, 3.189597888588007, 3.297227103769741, 3.7753802587421466, 1.3516737472112883, 11.97597461008888, 9.413985095588899, 26.61702904431985, 19.829025849688175, 13.023209350337572, 6.694572125142334, 24.73081907240881, 2.586324870797366, 1.115701720776538, 1.1156945632337385, 1.1156870377344337, 1.1156839387116066, 1.115662246690871, 1.1156563602489864, 1.7698731294353143, 1.7906134002636678, 1.9217810533180204, 1.9217083878070365, 1.967179132739199, 6.426469529155723, 2.3510083938524406, 2.368978394658941, 2.431452419100923, 2.4395320645698324, 2.514269398787078, 2.703463627699615, 3.2711923608431546, 3.3432902129773847, 4.161180775590374, 4.352288149750181, 4.4587318130514415, 5.874860472854072, 8.021962192693037, 8.964245937659589, 9.164863472239988, 9.413985095588899, 11.352700467262776, 11.909266231047347, 14.581282073279283, 18.071637920912835, 13.023209350337572, 1.0531413363091904, 1.0531388073375092, 1.0531371326951842, 1.0531284812245785, 1.05312839120438, 1.0531281110803843, 1.0531275033541139, 1.0531272762810118, 1.576572800842409, 1.821908408001472, 1.8277255282102762, 2.2875852733319197, 2.4395320645698324, 2.4984198276993004, 2.5907014365363876, 2.734800330421669, 3.232670939827168, 1.3665031310049514, 1.255944861649225, 3.7744038622736515, 3.9137172331025853, 4.001529695941268, 1.4074224549233767, 1.4119001425749724, 1.4137319372641173, 2.368978394658941, 4.520345922285936, 1.4277120563661028, 1.4292989385527346, 1.2817349152592885, 2.2634405717940362, 6.174133643284181, 7.17104117999721, 11.446956733370719, 8.964245937659589, 11.352700467262776, 11.909266231047347, 19.829025849688175, 24.73081907240881, 26.61702904431985], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.8686, -5.087, -4.8686, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -5.5254, -4.4756, -4.1942, -4.8686, -4.8687, -4.5281, -4.9766, -4.5179, -3.4423, -4.0875, -4.4756, -4.9385, -4.8687, -4.4756, -5.2889, -4.6008, -4.8687, -3.9984, -5.119, -4.5573, -4.9523, -5.1662, -4.3685, -4.9945, -4.7035, -4.4756, -4.7603, -4.8687, -4.8686, -4.4756, -4.7408, -4.8687, -4.8687, -4.8687, -4.7397, -4.7723, -4.8581, -4.8633, -4.7396, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3964, -5.3965, -5.3965, -5.3965, -5.3965, -5.3965, -4.4126, -5.0002, -4.0652, -4.6519, -4.822, -3.7794, -4.2527, -3.4565, -3.8574, -5.0751, -4.1402, -4.7396, -4.3867, -4.2775, -4.8904, -5.0215, -3.9852, -4.6108, -4.5464, -5.0407, -4.7759, -5.0437, -5.0099, -4.9305, -4.7397, -4.7953, -4.8088, -4.6105, -4.7216, -4.4899, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -4.6105, -4.6105, -3.7712, -4.6105, -4.8897, -3.7659, -4.7709, -4.2175, -3.7167, -4.7527, -4.0645, -3.8527, -4.728, -3.9361, -4.6105, -4.3259, -4.6105, -4.6105, -5.0522, -5.2672, -5.2673, -5.2673, -5.2673, -5.2673, -5.2673, -4.5301, -4.6504, -5.1868, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.1869, -5.187, -5.1965, -5.1966, -5.1971, -5.1984, -4.1371, -4.6778, -4.4131, -4.8069, -4.006, -4.314, -3.9044, -3.8476, -4.1208, -4.1371, -4.4922, -4.4111, -4.5578, -4.7735, -4.2109, -4.545, -4.7539, -5.0088, -5.0597, -5.0885, -5.1344, -5.1869, -5.1869, -5.1869, -4.4778, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1346, -5.1347, -5.1347, -5.1347, -5.1347, -5.1347, -5.1347, -5.1347, -5.1347, -4.4779, -5.2701, -5.272, -5.2892, -4.5906, -5.2971, -5.3167, -3.1726, -4.4778, -4.3355, -4.9568, -4.1526, -4.543, -3.7611, -3.8034, -4.4779, -4.4778, -4.4632, -4.8744, -4.8848, -4.7928, -4.7495, -4.9072, -4.9293, -4.7756, -4.7764, -4.9134, -5.1179, -5.1186, -5.1346, -5.1346, -5.1346, -4.4803, -5.137, -5.137, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -5.1371, -4.4803, -4.4803, -2.8063, -3.5865, -4.4803, -4.4557, -4.0873, -4.0773, -4.2193, -4.4803, -4.4803, -4.4237, -4.4803, -4.4803, -4.3731, -4.4803, -4.3997, -4.4803, -4.9435, -4.9083, -5.0972, -5.1029, -5.0873, -5.1083, -5.1371, -4.438, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.043, -5.043, -5.043, -5.043, -5.043, -5.043, -5.043, -5.043, -5.043, -4.3862, -4.3862, -4.3862, -3.7117, -3.3126, -4.3862, -4.3861, -3.9931, -4.3861, -3.9932, -4.3862, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -5.0429, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -3.5284, -4.2028, -4.5431, -4.2028, -5.0523, -5.058, -5.0625, -5.0831, -5.0882, -5.0678, -5.0888, -5.1216, -5.1244, -4.5074, -3.8098, -4.8596, -4.8596, -3.6895, -4.3115, -4.485, -4.3604, -4.2592, -4.2924, -4.0273, -4.3685, -4.7151, -4.8401, -4.8596, -4.8596, -4.8596, -4.8596, -4.8596, -4.603, -4.603, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6032, -3.9463, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -3.9463, -3.9463, -3.9464, -4.603, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -4.6031, -3.9369, -3.9369, -4.5937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5938, -4.5938, -3.9369, -4.5938, -3.937, -3.937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5938, -3.937, -3.0432, -4.5937, -4.5938, -4.5937, -4.5937, -4.5937, -4.5938, -4.5938, -3.9369, -3.937, -3.9369, -3.937, -4.5937, -4.5937, -4.5937, -4.5937, -4.5937, -3.9098, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5667, -4.5667, -4.5668, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -4.5666, -3.9098, -4.5666, -4.5666, -3.8503, -4.5666, -4.5667, -4.5666, -4.5667, -5.6496, -3.7349, -4.349, -4.261, -4.4626, -4.5666, -4.5666, -4.5666, -3.3587, -4.4085, -4.4085, -4.4085, -4.4085, -4.4086, -4.4086, -4.4086, -4.4085, -4.4085, -4.4086, -4.4087, -3.3587, -4.4085, -4.4085, -4.4085, -4.4087, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4085, -4.4086, -4.4085, -4.4086, -4.4085, -4.4085, -4.4086, -4.4086, -4.4006, -4.4006, -4.4006, -4.4007, -4.4007, -4.4007, -4.4007, -4.4007, -4.4007, -4.4006, -4.4006, -4.4006, -4.4007, -4.4006, -4.4006, -4.4006, -4.4007, -5.2678, -5.4627, -4.4006, -4.4007, -4.4008, -5.4663, -5.4907, -5.5009, -5.021, -4.4007, -5.5817, -5.5912, -5.7373, -5.1997, -4.4007, -4.4007, -4.2394, -4.4007, -4.4007, -4.4008, -4.235, -4.2156, -4.4006], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4948, 1.3629, 1.3024, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2999, 1.2414, 1.2122, 1.2531, 1.253, 1.1808, 1.1557, 1.0039, 0.543, 0.7416, 0.8899, 1.0319, 0.9724, 0.7634, 1.1798, 0.7933, 0.9275, 0.2813, 0.994, 0.4942, 0.822, 1.0018, 0.2185, 0.7612, 0.4378, 0.1205, 0.3133, 0.4281, 0.3798, -0.4168, 0.0431, -0.0216, -0.0792, -0.1602, 1.748, 1.7175, 1.6398, 1.6375, 1.5753, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5262, 1.5092, 1.5136, 1.3178, 1.408, 1.3748, 1.0677, 1.1937, 0.916, 0.9321, 1.3741, 0.6972, 1.088, 0.6869, 0.5064, 1.0714, 1.1721, 0.0, 0.5738, 0.4782, 1.0722, 0.6805, 0.9442, 0.771, 0.3661, -0.1436, -0.2082, -0.7501, 1.8435, 1.736, 1.6833, 1.6293, 1.6293, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.6292, 1.5828, 1.5828, 1.4636, 1.5436, 1.5727, 1.0715, 1.4224, 1.0309, 0.563, 1.2761, 0.6356, 0.1326, 1.0641, 0.1227, 0.7732, 0.2612, 0.2365, 0.098, 0.7144, 0.984, 1.2066, 1.2035, 0.5047, 0.9491, 1.2467, 2.0238, 1.9373, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.7865, 1.777, 1.7769, 1.7765, 1.7751, 1.7185, 1.7005, 1.6476, 1.5975, 1.0186, 0.8707, 0.3753, 0.1377, 0.4663, 0.459, 0.7467, 0.3729, 0.6169, 1.0008, -0.1521, 0.5065, 0.0752, 0.7579, -0.2126, 0.1463, -0.3449, 0.6053, 0.5941, 0.9201, 2.0999, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8568, 1.8443, 1.7218, 1.7198, 1.6913, 1.689, 1.6829, 1.6752, 1.5359, 1.6188, 1.6031, 1.5858, 1.1442, 1.3125, 0.6114, 0.4763, 1.0183, 0.6634, 0.5882, 1.3452, 1.3316, 0.9881, 0.4352, 0.8485, 0.9179, 0.0714, 0.0527, -0.2133, 1.4481, 1.1242, 1.1378, 1.3971, 0.162, 2.101, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.8571, 1.7994, 1.7602, 1.2525, 1.0096, 1.4221, 1.3914, 0.7022, 0.5097, 0.6098, 0.9138, 0.8163, 0.7176, 0.5933, 0.5711, 0.327, 0.3571, -0.0272, -0.2006, 0.2955, -0.1998, 0.0775, 0.3534, -1.102, -0.3244, 0.8015, 2.1053, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.9208, 1.8638, 1.8341, 1.6876, 1.0722, 0.6727, 1.4071, 1.11, 0.3793, 0.9105, 0.0656, 0.2099, 1.5164, 0.7153, 1.5182, 1.5046, 1.4724, 1.1503, 1.4719, 0.9888, 1.5182, 1.594, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.1504, 2.0889, 2.0556, 2.0529, 2.0389, 1.9547, 1.9289, 1.924, 1.9235, 1.9183, 1.9182, 1.8951, 1.8845, 1.8559, 1.7438, 1.365, 1.7798, 1.7321, 0.683, 1.2161, 1.262, 1.0861, 0.9254, 0.7322, 0.0315, 0.2185, 0.5815, 1.3435, 1.3492, 1.237, 1.3139, 0.2817, 1.6658, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.4632, 2.1422, 2.0363, 2.0175, 2.0111, 2.005, 2.0049, 1.981, 1.8006, 1.7191, 1.7009, 1.6832, 1.6694, 1.6639, 1.5038, 1.4478, 1.4374, 0.1124, 1.4287, 0.226, 1.1902, 0.8533, 0.9245, 1.4935, 0.5717, 1.3674, 0.5382, 0.1054, 0.6453, 1.4257, 0.097, 2.8057, 2.8057, 2.5199, 2.5199, 2.5199, 2.5199, 2.5199, 2.5199, 2.5199, 2.5199, 2.3736, 2.2178, 2.21, 2.1037, 2.065, 2.0631, 2.0432, 2.0056, 1.8182, 1.7229, 1.7155, 1.6802, 1.6569, 1.5774, 1.3849, 1.3179, 1.2587, 1.1645, 0.8626, 0.7893, 0.7716, 0.3427, 0.1218, 0.0483, 0.581, 0.5909, 0.4577, 0.4798, 0.2533, 2.9077, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6007, 2.6006, 2.6006, 2.6006, 2.1787, 2.1258, 2.1104, 2.1033, 2.0724, 2.0527, 1.8727, 1.8621, 1.7631, 1.7188, 1.6715, 1.5804, 1.5403, 1.5071, 1.3717, 1.3159, 1.049, 0.6756, -0.2757, -0.1829, 0.1335, 0.7989, -0.5078, 2.9579, 2.7488, 2.7488, 2.7488, 2.7488, 2.7488, 2.7488, 2.2874, 2.2757, 2.2051, 2.2051, 2.1815, 2.0477, 2.0035, 1.9958, 1.9698, 1.9663, 1.9363, 1.8637, 1.6731, 1.6514, 1.4325, 1.3876, 1.3634, 1.0876, 0.7761, 0.665, 0.6429, 0.6161, 0.4288, 0.381, 0.1786, -0.0361, 0.2915, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.8144, 2.4109, 2.2663, 2.2631, 2.0387, 1.9744, 1.9505, 1.9143, 1.8601, 1.6929, 1.6868, 1.5762, 1.538, 1.5017, 1.4793, 1.4588, 1.4312, 1.4197, 1.3833, 1.3576, 1.3291, 1.3184, 1.2813, 1.2502, 1.0458, 0.8961, 0.5897, 0.6729, 0.4367, 0.3887, 0.0447, -0.1568, -0.4154]}, \"token.table\": {\"Topic\": [1, 1, 2, 3, 5, 6, 10, 12, 4, 6, 7, 2, 2, 6, 1, 2, 8, 6, 7, 7, 6, 1, 4, 1, 3, 1, 3, 4, 11, 12, 1, 4, 5, 6, 7, 8, 9, 1, 8, 12, 10, 1, 5, 8, 2, 10, 10, 2, 4, 7, 1, 1, 2, 4, 5, 8, 9, 4, 5, 2, 4, 5, 5, 4, 2, 12, 8, 6, 7, 11, 1, 7, 9, 2, 3, 10, 1, 2, 3, 10, 1, 3, 7, 9, 7, 3, 5, 9, 5, 2, 1, 2, 8, 8, 6, 7, 4, 5, 6, 2, 1, 4, 9, 12, 9, 10, 4, 9, 7, 10, 12, 4, 4, 3, 7, 5, 1, 7, 9, 4, 1, 10, 5, 2, 3, 6, 8, 3, 3, 7, 1, 2, 3, 5, 6, 7, 8, 9, 12, 1, 6, 9, 8, 1, 4, 5, 3, 3, 5, 6, 2, 6, 7, 3, 1, 4, 7, 12, 6, 10, 3, 8, 7, 12, 3, 5, 4, 4, 3, 6, 8, 5, 4, 6, 4, 3, 1, 8, 6, 1, 4, 7, 10, 3, 4, 9, 3, 3, 7, 4, 5, 9, 3, 5, 1, 5, 6, 7, 12, 6, 1, 5, 12, 3, 5, 8, 5, 2, 3, 6, 7, 6, 2, 8, 1, 2, 4, 6, 8, 9, 10, 4, 1, 8, 1, 2, 8, 9, 1, 3, 4, 5, 6, 10, 12, 6, 7, 1, 1, 5, 1, 2, 4, 5, 6, 7, 11, 9, 3, 8, 2, 6, 8, 9, 6, 6, 3, 8, 2, 3, 4, 5, 10, 1, 2, 4, 5, 8, 10, 12, 5, 1, 7, 3, 1, 2, 3, 6, 10, 12, 1, 5, 6, 9, 2, 3, 3, 8, 9, 9, 6, 5, 9, 3, 4, 7, 9, 2, 3, 5, 9, 7, 9, 1, 8, 7, 1, 3, 1, 4, 8, 9, 5, 7, 2, 3, 9, 2, 4, 1, 2, 3, 4, 5, 6, 7, 8, 12, 4, 1, 6, 6, 9, 3, 4, 9, 8, 10, 12, 2, 3, 3, 2, 12, 9, 4, 1, 3, 5, 6, 8, 9, 10, 12, 12, 3, 6, 3, 6, 2, 7, 10, 5, 2, 10, 1, 3, 12, 1, 3, 4, 5, 6, 9, 7, 7, 2, 7, 9, 8, 8, 2, 5, 7, 8, 1, 2, 4, 8, 10, 11, 12, 1, 2, 4, 5, 6, 7, 4, 7, 2, 3, 4, 8, 1, 7, 1, 7, 3, 6, 10, 1, 7, 12, 1, 8, 3, 6, 3, 6, 7, 1, 1, 7, 6, 6, 3, 1, 3, 10, 1, 5, 8, 5, 3, 5, 3, 2, 3, 5, 10, 4, 2, 3, 7, 5, 4, 5, 9, 1, 5, 3, 5, 6, 4, 5, 4, 12, 9, 1, 5, 5, 3, 1, 4, 8, 9, 7, 2, 3, 4, 6, 8, 9, 10, 1, 3, 4, 7, 9, 5, 12, 4, 9, 5, 2, 12, 1, 2, 3, 5, 2, 5, 1, 3, 5, 7, 5, 1, 10, 5, 4, 1, 2, 3, 4, 5, 6, 10, 12, 1, 2, 6, 8, 1, 2, 2, 5, 12, 10, 2, 1, 2, 4, 1, 2, 10, 7, 8, 7, 9, 1, 8, 10, 8, 5, 5, 8, 9, 4, 1, 6, 7, 6, 3, 1, 2, 5, 6, 7, 8, 3, 12, 1, 2, 3, 4, 8, 9, 3, 5, 8, 9, 10, 6, 4, 4, 6, 2, 10, 2, 3, 6, 3, 1, 8, 1, 8, 2, 1, 1, 2, 3, 7, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 8, 3, 8, 9, 6, 1, 10, 6, 8, 3, 2, 5, 3, 5, 10, 7, 1, 3, 4, 8, 2, 4, 4, 7, 1, 10, 5, 2, 5, 5, 6, 3, 9, 1, 6, 5, 12, 6, 1, 2, 1, 4, 9, 8, 2, 1, 2, 5, 7, 8, 2, 5, 1, 2, 1, 2, 3, 1, 3, 4, 5, 6, 6, 6, 3, 8, 8, 2, 3, 5, 7, 1, 12, 2, 5, 7, 12, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 1, 2, 3, 4, 5, 6, 7, 8, 10, 1, 2, 3, 5, 6, 7, 8, 9, 10, 12, 1, 4, 12, 1, 2, 7, 8, 9, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 3, 12, 7, 4, 7, 2, 1, 2, 4, 5, 2, 5, 9, 1, 4, 3, 1, 2, 1, 12, 8, 2, 6, 1, 2, 3, 6, 4, 7, 7, 8, 2, 7, 4, 7, 5, 8, 1, 3, 4, 4, 4, 1, 3, 8, 2, 6, 7, 1, 2, 4, 6, 1, 2, 3, 7, 1, 3, 6, 11, 3, 1, 9, 1, 2, 3, 5, 7, 1, 7, 4, 4, 6, 1, 3, 4, 5, 6, 8, 9, 13, 1, 2, 8, 2, 7, 10, 1, 2, 3, 4, 5, 7, 10], \"Freq\": [0.6430876435021979, 0.22310855970582236, 0.22310855970582236, 0.11155427985291118, 0.11155427985291118, 0.11155427985291118, 0.11155427985291118, 0.11155427985291118, 0.7457014532355963, 0.7613846304657209, 0.7385536237084043, 0.7087911212648803, 0.548875012381628, 0.7613630274502687, 0.33509503304126004, 0.33509503304126004, 0.33509503304126004, 0.493749451077447, 0.493749451077447, 0.7385509332200977, 0.7613747308225235, 0.7073476757801909, 0.7457141395623903, 0.6430859435178876, 0.5471281024231293, 0.2242790196694126, 0.2242790196694126, 0.2242790196694126, 0.2242790196694126, 0.2242790196694126, 0.23872946991575456, 0.11936473495787728, 0.11936473495787728, 0.11936473495787728, 0.11936473495787728, 0.11936473495787728, 0.11936473495787728, 0.6430620607499927, 0.565012250521626, 0.565012250521626, 0.5920325533655214, 0.3471365052667681, 0.3471365052667681, 0.3471365052667681, 0.7087777623252222, 0.8579405124031553, 0.8579538879315269, 0.3917552918146859, 0.3917552918146859, 0.7385558821512272, 0.6430826523194986, 0.45016972466410304, 0.3591554111374844, 0.3591554111374844, 0.3591554111374844, 0.5239985447505474, 0.5239985447505474, 0.48767477890807015, 0.24383738945403508, 0.7087643889678162, 0.7456950717744415, 0.7592781616147476, 0.7510202503406875, 0.49019016802669646, 0.7087799457866463, 0.8963333474626768, 0.770828253650646, 0.7613561206576018, 0.738564988356355, 0.6380606976709571, 0.6430872594307421, 0.7385608160411805, 0.8182959726956364, 0.4524913213680983, 0.4524913213680983, 0.6342872333365581, 0.275770805719047, 0.275770805719047, 0.275770805719047, 0.275770805719047, 0.22910601571745776, 0.22910601571745776, 0.22910601571745776, 0.22910601571745776, 0.7385553826331687, 0.3699444991683923, 0.3699444991683923, 0.3699444991683923, 0.7592891626507626, 0.4709417556084067, 0.3385072104654301, 0.3385072104654301, 0.3385072104654301, 0.7711637538307141, 0.7613816191815728, 0.7385529927799382, 0.26494250125041285, 0.5298850025008257, 0.26494250125041285, 0.7087770691599456, 0.4806328078155285, 0.24031640390776424, 0.24031640390776424, 0.24031640390776424, 0.8182933359054643, 0.857951805536791, 0.5206716430159585, 0.5206716430159585, 0.42534939586556164, 0.42534939586556164, 0.42534939586556164, 0.7456869525852149, 0.7456943013550228, 0.6905286687935241, 0.7385476163427077, 0.759283392340849, 0.35115594125108857, 0.35115594125108857, 0.8182807714114699, 0.7457096989351464, 0.3263153652692724, 0.3263153652692724, 0.7592856009470275, 0.48589813135373316, 0.1619660437845777, 0.1619660437845777, 0.1619660437845777, 0.6905221810471095, 0.47165800869160746, 0.47165800869160746, 0.05533532734422381, 0.3320119640653429, 0.05533532734422381, 0.16600598203267145, 0.11067065468844763, 0.11067065468844763, 0.11067065468844763, 0.05533532734422381, 0.05533532734422381, 0.5470287754398919, 0.27351438771994596, 0.27351438771994596, 0.7551273408826048, 0.7105187191676875, 0.7456891333750163, 0.7592922781883706, 0.6905220285980515, 0.24178257446509183, 0.24178257446509183, 0.24178257446509183, 0.7087899591264759, 0.7613743690863328, 0.7385623973186701, 0.6905224571175006, 0.45952839774976734, 0.22976419887488367, 0.22976419887488367, 0.22976419887488367, 0.5443968605475167, 0.5443968605475167, 0.6905350655591429, 0.511260914334586, 0.5505020704298457, 0.89632861824093, 0.6905177073135432, 0.7592722240480412, 0.7456948494209025, 0.7962132976816076, 0.6836341191476414, 0.3418170595738207, 0.7734867369584876, 0.7592947891625981, 0.3726413054545782, 0.3726413054545782, 0.7456791574156013, 0.6905245602919802, 0.6430848462556672, 0.7734775058317798, 0.7613786304052872, 0.22122200760562602, 0.22122200760562602, 0.22122200760562602, 0.22122200760562602, 0.36794358955728385, 0.36794358955728385, 0.36794358955728385, 0.6905245615446284, 0.47140456369092404, 0.47140456369092404, 0.49616129693729133, 0.49616129693729133, 0.8182749179348678, 0.6699689890161825, 0.7592972242166417, 0.1702168084877408, 0.1702168084877408, 0.1702168084877408, 0.1702168084877408, 0.1702168084877408, 0.761368770822385, 0.3698958586881018, 0.3698958586881018, 0.3698958586881018, 0.4710121827289041, 0.4710121827289041, 0.7734718598176004, 0.7596530831659609, 0.7087697345624263, 0.3093417234893274, 0.3093417234893274, 0.3093417234893274, 0.761383738476911, 0.7087744956643568, 0.7735015382962995, 0.12342697857636131, 0.12342697857636131, 0.12342697857636131, 0.12342697857636131, 0.24685395715272263, 0.12342697857636131, 0.12342697857636131, 0.7456964431964186, 0.6430756449072828, 0.7734779985867581, 0.3154154012350572, 0.3154154012350572, 0.7734703606480429, 0.8182640091246854, 0.3273371184510148, 0.10911237281700495, 0.10911237281700495, 0.10911237281700495, 0.10911237281700495, 0.10911237281700495, 0.10911237281700495, 0.4937481616035932, 0.4937481616035932, 0.6430736550932309, 0.6363615586436949, 0.31818077932184746, 0.16700102205587067, 0.25050153308380596, 0.16700102205587067, 0.08350051102793533, 0.08350051102793533, 0.25050153308380596, 0.08350051102793533, 0.8182774835262981, 0.4764325615832739, 0.4764325615832739, 0.2648739812855759, 0.2648739812855759, 0.2648739812855759, 0.2648739812855759, 0.7613688353919724, 0.7613766714651499, 0.36481941604784235, 0.36481941604784235, 0.24305691127021992, 0.24305691127021992, 0.24305691127021992, 0.24305691127021992, 0.24305691127021992, 0.8103893564484906, 0.24931556045249623, 0.24931556045249623, 0.12465778022624811, 0.12465778022624811, 0.12465778022624811, 0.12465778022624811, 0.7592831742451995, 0.7317948838248045, 0.7385516270061269, 0.6905179596624244, 0.08808476915987089, 0.26425430747961265, 0.35233907663948355, 0.08808476915987089, 0.08808476915987089, 0.08808476915987089, 0.30739801064730615, 0.15369900532365308, 0.15369900532365308, 0.15369900532365308, 0.7087825584433328, 0.6905261695369795, 0.2899514353495237, 0.2899514353495237, 0.2899514353495237, 0.818275693332887, 0.7613652776892551, 0.7592752699522332, 0.8182797275006365, 0.2908132144015575, 0.2908132144015575, 0.2908132144015575, 0.2908132144015575, 0.45107769881518384, 0.45107769881518384, 0.38881634092246936, 0.38881634092246936, 0.4850582444041482, 0.8182979351783244, 0.37476542080391795, 0.37476542080391795, 0.738560146743783, 0.6430756337187041, 0.44734673660812224, 0.6430827830731629, 0.7458470219292385, 0.7734839964305922, 0.8182838590888434, 0.7592817648116851, 0.7385533566526594, 0.7087765360494737, 0.8872025032682451, 0.8182738942144261, 0.46486122417916964, 0.7457023692295938, 0.20574322511033558, 0.13716215007355703, 0.13716215007355703, 0.13716215007355703, 0.06858107503677852, 0.13716215007355703, 0.06858107503677852, 0.06858107503677852, 0.06858107503677852, 0.7457025751052707, 0.6430756303649441, 0.7613613898064482, 0.5038454484634278, 0.818269729918342, 0.31351914408329595, 0.31351914408329595, 0.31351914408329595, 0.750887150798987, 0.38664902901069004, 0.38664902901069004, 0.7087861636717634, 0.6905238330716313, 0.6905144045021917, 0.4635362061335185, 0.8963111911020261, 0.5936040535015971, 0.7456943571307614, 0.1548666162957164, 0.1548666162957164, 0.387166540739291, 0.0774333081478582, 0.0774333081478582, 0.0774333081478582, 0.0774333081478582, 0.0774333081478582, 0.8963026557211067, 0.6905317126276621, 0.7613621784492312, 0.683622673371716, 0.341811336685858, 0.3032851449197095, 0.3032851449197095, 0.8579410209207087, 0.7592957459021703, 0.7087687966838428, 0.8579295189848188, 0.6430785989063412, 0.5203703154676621, 0.5203703154676621, 0.26572955516043767, 0.26572955516043767, 0.13286477758021883, 0.13286477758021883, 0.13286477758021883, 0.13286477758021883, 0.7385500167520483, 0.7385570964348831, 0.9195339764355358, 0.5175117686831131, 0.5175117686831131, 0.7734787091307707, 0.7704733444535561, 0.4742546562879234, 0.2371273281439617, 0.2371273281439617, 0.2371273281439617, 0.10622493979394221, 0.21244987958788442, 0.21244987958788442, 0.10622493979394221, 0.10622493979394221, 0.10622493979394221, 0.10622493979394221, 0.3948532840157947, 0.13161776133859823, 0.26323552267719647, 0.13161776133859823, 0.13161776133859823, 0.13161776133859823, 0.7457200219748412, 0.7385487846840778, 0.2288506348402484, 0.2288506348402484, 0.2288506348402484, 0.2288506348402484, 0.3332585691296776, 0.3332585691296776, 0.6430704785159101, 0.7385563145332915, 0.38385364991503185, 0.38385364991503185, 0.38385364991503185, 0.622425731866109, 0.15560643296652726, 0.15560643296652726, 0.6430622753364066, 0.7734696690581998, 0.6905399791356391, 0.7613692128488632, 0.25551156111686013, 0.25551156111686013, 0.25551156111686013, 0.6430756697935819, 0.7004213458456456, 0.7385560018702425, 0.7613659903071015, 0.7613699696426826, 0.6905410771875777, 0.29343013530689394, 0.29343013530689394, 0.29343013530689394, 0.6368336053176831, 0.2122778684392277, 0.2122778684392277, 0.7595685130614201, 0.6905306926144139, 0.7592798075797039, 0.6905349281423551, 0.350893418629378, 0.350893418629378, 0.350893418629378, 0.8579457740063194, 0.7456841053862631, 0.7719916976129368, 0.44521206081307885, 0.7385531772049083, 0.750629955162203, 0.38183226014349947, 0.38183226014349947, 0.38183226014349947, 0.6430792777804267, 0.7593038941328365, 0.6905223770132844, 0.37257594881293415, 0.37257594881293415, 0.554445481686418, 0.7592844167826058, 0.4112768122231113, 0.4112768122231113, 0.8182703904779081, 0.6363761931282472, 0.3181880965641236, 0.7592819417750635, 0.6905316571501174, 0.21874538558585696, 0.21874538558585696, 0.21874538558585696, 0.21874538558585696, 0.7385652418972665, 0.3271512400106894, 0.1635756200053447, 0.1635756200053447, 0.1635756200053447, 0.1635756200053447, 0.1635756200053447, 0.1635756200053447, 0.15211231643007248, 0.30422463286014495, 0.15211231643007248, 0.15211231643007248, 0.15211231643007248, 0.3977298536435337, 0.3977298536435337, 0.5987470650080482, 0.2993735325040241, 0.7592910889497716, 0.5337747452988792, 0.8962969056855011, 0.4413196376031365, 0.22065981880156826, 0.22065981880156826, 0.22065981880156826, 0.708778115269973, 0.7592887132754284, 0.6430806400322031, 0.6905312715233253, 0.4928683644313846, 0.4928683644313846, 0.7592862626689583, 0.5129826045309068, 0.5129826045309068, 0.7592987372749531, 0.7801925250649079, 0.1679364589890533, 0.3358729179781066, 0.08396822949452665, 0.08396822949452665, 0.08396822949452665, 0.1679364589890533, 0.08396822949452665, 0.08396822949452665, 0.3419341569125822, 0.3419341569125822, 0.3419341569125822, 0.7555244793638661, 0.6430764504284914, 0.7087811335675556, 0.5982130992507795, 0.29910654962538974, 0.29910654962538974, 0.8579402871373186, 0.7087734665772221, 0.44960230931086365, 0.22480115465543182, 0.22480115465543182, 0.2605418101656649, 0.5210836203313298, 0.8579533916354312, 0.738556362880099, 0.7734833667371515, 0.5174528854602749, 0.5174528854602749, 0.192124478999851, 0.576373436999553, 0.192124478999851, 0.7734779087847816, 0.7595764668947655, 0.31029557193904955, 0.31029557193904955, 0.31029557193904955, 0.7457005068394701, 0.2649275887052974, 0.2649275887052974, 0.2649275887052974, 0.7613769167315292, 0.5233527577917211, 0.1394286683278743, 0.1394286683278743, 0.1394286683278743, 0.1394286683278743, 0.1394286683278743, 0.1394286683278743, 0.4371421741771739, 0.8963087014353477, 0.1310715476662186, 0.1310715476662186, 0.5242861906648744, 0.1310715476662186, 0.1310715476662186, 0.8182623865581997, 0.2579124128109364, 0.2579124128109364, 0.2579124128109364, 0.2579124128109364, 0.2579124128109364, 0.7613684037145217, 0.7457048075965524, 0.7456960752104115, 0.7613756120429407, 0.7087841259232172, 0.592039631680369, 0.2783374837306893, 0.2783374837306893, 0.2783374837306893, 0.6905169612234106, 0.3587509567314521, 0.3587509567314521, 0.6430815572467391, 0.770775416715053, 0.7087804571363356, 0.6430750815398389, 0.15201153967155698, 0.45603461901467096, 0.15201153967155698, 0.15201153967155698, 0.15201153967155698, 0.12130613188412269, 0.040435377294707565, 0.12130613188412269, 0.08087075458941513, 0.040435377294707565, 0.28304764106295294, 0.08087075458941513, 0.08087075458941513, 0.040435377294707565, 0.040435377294707565, 0.040435377294707565, 0.7558769785313871, 0.690522936732447, 0.5339552706803652, 0.5339552706803652, 0.7613834836367261, 0.6685759884654996, 0.3342879942327498, 0.5091341458103623, 0.5091341458103623, 0.6905355571213767, 0.47942679888410683, 0.47942679888410683, 0.6905250106618132, 0.5433346646342122, 0.5433346646342122, 0.7385554129738201, 0.22308489746661847, 0.22308489746661847, 0.22308489746661847, 0.22308489746661847, 0.7087841032540265, 0.745697097575596, 0.7457165654030014, 0.7385545046757954, 0.38432559632015334, 0.38432559632015334, 0.7592764082406621, 0.48472472061334165, 0.48472472061334165, 0.5020142850889641, 0.7613722274004021, 0.50527668785744, 0.50527668785744, 0.6430850591753435, 0.7613639481943835, 0.5584678411614422, 0.5584678411614422, 0.761381432385029, 0.6996437015566318, 0.7087598696757407, 0.6430729062257026, 0.7458111569605776, 0.8182687280475389, 0.7734731376601801, 0.7087876574374735, 0.24990443055172004, 0.24990443055172004, 0.24990443055172004, 0.24990443055172004, 0.24990443055172004, 0.40025298747363125, 0.40025298747363125, 0.36565740791972684, 0.36565740791972684, 0.6430818076238014, 0.27116870699821766, 0.27116870699821766, 0.4481242331728881, 0.14937474439096268, 0.14937474439096268, 0.14937474439096268, 0.14937474439096268, 0.7613766338763885, 0.5630670319663514, 0.3621954655587734, 0.3621954655587734, 0.7734784925909468, 0.3497757475879579, 0.3497757475879579, 0.3497757475879579, 0.7385645563265052, 0.40991467770534595, 0.40991467770534595, 0.3056989286139836, 0.3056989286139836, 0.3056989286139836, 0.3056989286139836, 0.2521556045113849, 0.20172448360910794, 0.15129336270683094, 0.15129336270683094, 0.050431120902276985, 0.050431120902276985, 0.050431120902276985, 0.050431120902276985, 0.050431120902276985, 0.050431120902276985, 0.050431120902276985, 0.20760530597661492, 0.13840353731774327, 0.06920176865887163, 0.13840353731774327, 0.06920176865887163, 0.20760530597661492, 0.06920176865887163, 0.06920176865887163, 0.06920176865887163, 0.07678598823830465, 0.07678598823830465, 0.23035796471491396, 0.07678598823830465, 0.1535719764766093, 0.07678598823830465, 0.07678598823830465, 0.07678598823830465, 0.23035796471491396, 0.07678598823830465, 0.7082653863723225, 0.42212288734020675, 0.42212288734020675, 0.3512852361647701, 0.17564261808238504, 0.17564261808238504, 0.17564261808238504, 0.17564261808238504, 0.3005594646449553, 0.11270979924185824, 0.15027973232247765, 0.11270979924185824, 0.037569933080619414, 0.15027973232247765, 0.037569933080619414, 0.037569933080619414, 0.037569933080619414, 0.037569933080619414, 0.5203506394620063, 0.5203506394620063, 0.738546545242739, 0.36173909033721885, 0.36173909033721885, 0.7087921351025389, 0.22629812214242803, 0.22629812214242803, 0.22629812214242803, 0.22629812214242803, 0.3751224150155753, 0.3751224150155753, 0.3751224150155753, 0.8836105639012959, 0.7458158999139094, 0.6905255747388117, 0.6431756401994294, 0.3215878200997147, 0.5083421145320659, 0.5083421145320659, 0.7535091799083031, 0.708762801427881, 0.7613674846440017, 0.3429946677401318, 0.3429946677401318, 0.35832644532184255, 0.35832644532184255, 0.48711195555246695, 0.48711195555246695, 0.7385595922752369, 0.7734900800773854, 0.9175853301871656, 0.73856635593351, 0.7456831313399038, 0.7385619366634326, 0.7593067999963631, 0.7734786958402796, 0.3286567705737185, 0.657313541147437, 0.7456858118040847, 0.7458243860224605, 0.745704546819627, 0.6430719919159934, 0.6905374215425024, 0.7734744600734156, 0.7087895119404491, 0.7613692225133208, 0.7385547026564471, 0.6317206094317639, 0.21057353647725463, 0.21057353647725463, 0.7613564823462599, 0.6430796627493345, 0.70877716738766, 0.34178562680645025, 0.34178562680645025, 0.5239312398219569, 0.17464374660731896, 0.17464374660731896, 0.17464374660731896, 0.6905348563017253, 0.6430765653572681, 0.8182710894881133, 0.2788995279484336, 0.1394497639742168, 0.1394497639742168, 0.2788995279484336, 0.1394497639742168, 0.64307497733145, 0.7385640937165874, 0.7457067157829532, 0.5070547831603041, 0.761364782638965, 0.3494378543721588, 0.0873594635930397, 0.0873594635930397, 0.0873594635930397, 0.1747189271860794, 0.0873594635930397, 0.0873594635930397, 0.0873594635930397, 0.44150499212297506, 0.44150499212297506, 0.773473560428505, 0.7087771719440487, 0.5326300337095304, 0.5326300337095304, 0.17788383974812663, 0.35576767949625326, 0.17788383974812663, 0.08894191987406332, 0.08894191987406332, 0.08894191987406332, 0.08894191987406332], \"Term\": [\"30min\", \"able\", \"able\", \"able\", \"able\", \"able\", \"able\", \"able\", \"absolute\", \"abuse\", \"account\", \"accountable\", \"action\", \"actual\", \"addiction\", \"addiction\", \"addiction\", \"address\", \"address\", \"adjective\", \"advance\", \"advice\", \"amount\", \"anger\", \"annoying\", \"anxiety\", \"anxiety\", \"anxiety\", \"anxiety\", \"anxiety\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"apprehensive\", \"approach\", \"approach\", \"appt\", \"aspect\", \"aspect\", \"aspect\", \"assertive\", \"assessment\", \"astute\", \"attack\", \"attack\", \"attention\", \"audience\", \"available\", \"awful\", \"awful\", \"awful\", \"awkward\", \"awkward\", \"bad\", \"bad\", \"balance\", \"basic\", \"basis\", \"beam\", \"betterhelp\", \"blunt\", \"bomb\", \"breathing\", \"brick\", \"brief\", \"briley\", \"browning\", \"busy\", \"butt\", \"care\", \"care\", \"case\", \"change\", \"change\", \"change\", \"change\", \"chat\", \"chat\", \"chat\", \"chat\", \"chatting\", \"check\", \"check\", \"check\", \"choice\", \"christian\", \"chronic\", \"chronic\", \"chronic\", \"clam\", \"clarity\", \"clear\", \"client\", \"client\", \"client\", \"close\", \"comfortable\", \"comfortable\", \"comfortable\", \"comfortable\", \"compassion\", \"compatible\", \"complete\", \"complete\", \"complicated\", \"complicated\", \"complicated\", \"computer\", \"concerned\", \"confidence\", \"consistent\", \"console\", \"contact\", \"contact\", \"content\", \"convenient\", \"conversation\", \"conversation\", \"councilor\", \"counseling\", \"counseling\", \"counseling\", \"counseling\", \"counselling\", \"counsellor\", \"counsellor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"counselor\", \"couple\", \"couple\", \"couple\", \"current\", \"cuss\", \"cyndi\", \"daily\", \"darkness\", \"day\", \"day\", \"day\", \"dead\", \"deal\", \"definition\", \"depressed\", \"depression\", \"depression\", \"depression\", \"depression\", \"detail\", \"detail\", \"diagnosis\", \"different\", \"difficulty\", \"diggity\", \"direction\", \"disappoint\", \"discouraged\", \"dismissive\", \"disorder\", \"disorder\", \"distant\", \"divorce\", \"doctor\", \"doctor\", \"doubtful\", \"drop\", \"dynamic\", \"edlyne\", \"eleanor\", \"email\", \"email\", \"email\", \"email\", \"emotion\", \"emotion\", \"emotion\", \"energy\", \"enough\", \"enough\", \"entire\", \"entire\", \"excellent\", \"expectation\", \"experiance\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"face\", \"family\", \"family\", \"family\", \"fantastic\", \"fantastic\", \"father\", \"fault\", \"feedback\", \"feel\", \"feel\", \"feel\", \"few\", \"fill\", \"final\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"flag\", \"focus\", \"follow\", \"food\", \"food\", \"formulaic\", \"foxman\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"friend\", \"full\", \"full\", \"general\", \"goal\", \"goal\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"grandparent\", \"grateful\", \"grateful\", \"great\", \"great\", \"great\", \"great\", \"haley\", \"hand\", \"happy\", \"happy\", \"hard\", \"hard\", \"hard\", \"hard\", \"hard\", \"hassert\", \"health\", \"health\", \"health\", \"health\", \"health\", \"health\", \"hear\", \"heavy\", \"heck\", \"helmholdt\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"helpful\", \"helpful\", \"helpful\", \"helpful\", \"helping\", \"hesitant\", \"high\", \"high\", \"high\", \"hole\", \"hollywood\", \"homework\", \"honest\", \"hope\", \"hope\", \"hope\", \"hope\", \"horrible\", \"horrible\", \"hour\", \"hour\", \"humor\", \"husband\", \"illness\", \"illness\", \"immediate\", \"impact\", \"important\", \"incomplete\", \"individual\", \"informed\", \"input\", \"insightful\", \"insult\", \"intelligent\", \"intense\", \"interest\", \"interested\", \"invalided\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"jenning\", \"judgement\", \"judgemental\", \"judgmental\", \"kick\", \"kind\", \"kind\", \"kind\", \"lack\", \"last\", \"last\", \"leave\", \"lee\", \"left\", \"lengthy\", \"leslie\", \"less\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"lifesaver\", \"light\", \"listener\", \"live\", \"live\", \"long\", \"long\", \"lose\", \"loss\", \"love\", \"lovely\", \"managementcommunication\", \"manner\", \"manner\", \"many\", \"many\", \"many\", \"many\", \"many\", \"many\", \"mark\", \"material\", \"mean\", \"mechanism\", \"mechanism\", \"medical\", \"meditation\", \"meeting\", \"meeting\", \"meeting\", \"meeting\", \"mental\", \"mental\", \"mental\", \"mental\", \"mental\", \"mental\", \"mental\", \"message\", \"message\", \"message\", \"message\", \"message\", \"message\", \"metric\", \"min\", \"mind\", \"mind\", \"mind\", \"mind\", \"minute\", \"minute\", \"mistake\", \"modern\", \"money\", \"money\", \"money\", \"month\", \"month\", \"month\", \"mood\", \"mother\", \"motivation\", \"mouth\", \"much\", \"much\", \"much\", \"multiple\", \"mutual\", \"name\", \"narcissism\", \"narcissist\", \"necessary\", \"need\", \"need\", \"need\", \"negative\", \"negative\", \"negative\", \"negativity\", \"night\", \"nonjudgemental\", \"nonresponsive\", \"number\", \"number\", \"number\", \"observation\", \"offer\", \"online\", \"open\", \"opposite\", \"option\", \"other\", \"other\", \"other\", \"outlook\", \"pace\", \"page\", \"pandemic\", \"pandemic\", \"panic\", \"parenting\", \"party\", \"party\", \"passion\", \"past\", \"past\", \"patch\", \"path\", \"patient\", \"patient\", \"patient\", \"patient\", \"pejorative\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"people\", \"person\", \"person\", \"person\", \"person\", \"person\", \"personal\", \"personal\", \"phone\", \"phone\", \"pitied\", \"place\", \"pleasant\", \"point\", \"point\", \"point\", \"point\", \"popup\", \"position\", \"positive\", \"potential\", \"present\", \"present\", \"previous\", \"priority\", \"priority\", \"priscilla\", \"privacy\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"professional\", \"professional\", \"professional\", \"professionalism\", \"psychiatrist\", \"psychologist\", \"ptsd\", \"ptsd\", \"ptsd\", \"push\", \"quality\", \"question\", \"question\", \"question\", \"questionnaire\", \"questionnaire\", \"reach\", \"reading\", \"reaffirmation\", \"real\", \"real\", \"reason\", \"reason\", \"reason\", \"recommendation\", \"regard\", \"relationship\", \"relationship\", \"relationship\", \"remedy\", \"reply\", \"reply\", \"reply\", \"resource\", \"respond\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"responsive\", \"responsiveness\", \"right\", \"right\", \"right\", \"right\", \"right\", \"robin\", \"rough\", \"rough\", \"rough\", \"rough\", \"rough\", \"rude\", \"rule\", \"safe\", \"satisfied\", \"savili\", \"scared\", \"schedule\", \"schedule\", \"schedule\", \"schizoaffective\", \"second\", \"second\", \"section\", \"self\", \"sense\", \"sentence\", \"service\", \"service\", \"service\", \"service\", \"service\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"session\", \"setting\", \"shape\", \"share\", \"share\", \"shit\", \"short\", \"short\", \"show\", \"show\", \"sick\", \"side\", \"side\", \"simmon\", \"single\", \"single\", \"siouneh\", \"situation\", \"situation\", \"situation\", \"situation\", \"skeptical\", \"skill\", \"sleep\", \"slow\", \"specific\", \"specific\", \"spot\", \"stay\", \"stay\", \"step\", \"stereotypical\", \"story\", \"story\", \"straight\", \"stress\", \"stressful\", \"stressful\", \"stretch\", \"stuff\", \"style\", \"success\", \"suffering\", \"suggestion\", \"suicide\", \"superpower\", \"support\", \"support\", \"support\", \"support\", \"support\", \"sure\", \"sure\", \"survey\", \"survey\", \"swing\", \"system\", \"system\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talking\", \"technical\", \"technique\", \"technique\", \"terminology\", \"terrible\", \"terrible\", \"terrible\", \"testimonial\", \"text\", \"text\", \"thank\", \"thank\", \"thank\", \"thank\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapist\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"therapy\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thinking\", \"third\", \"third\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timely\", \"timely\", \"tip\", \"today\", \"today\", \"tonight\", \"tool\", \"tool\", \"tool\", \"tool\", \"tough\", \"tough\", \"tough\", \"toxic\", \"tragedy\", \"transition\", \"trauma\", \"trauma\", \"trigger\", \"trigger\", \"true\", \"trust\", \"truth\", \"type\", \"type\", \"unable\", \"unable\", \"unbelievable\", \"unbelievable\", \"underlying\", \"understandable\", \"understanding\", \"understatement\", \"understood\", \"unfortunate\", \"unhappiness\", \"unhappy\", \"unhelpful\", \"unhelpful\", \"unicorn\", \"unique\", \"unprofessional\", \"unrelated\", \"unwilling\", \"valid\", \"various\", \"verge\", \"vernacular\", \"video\", \"video\", \"video\", \"wall\", \"wanted\", \"warm\", \"waste\", \"waste\", \"week\", \"week\", \"week\", \"week\", \"weekend\", \"weird\", \"weirdo\", \"well\", \"well\", \"well\", \"well\", \"well\", \"wendy\", \"wish\", \"woman\", \"wonder\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worksheet\", \"worksheet\", \"worldview\", \"wreck\", \"wrong\", \"wrong\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 11, 3, 10, 5, 13, 7, 6, 2, 8, 12, 4, 9]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2261406699408689122736795683\", ldavis_el2261406699408689122736795683_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2261406699408689122736795683\", ldavis_el2261406699408689122736795683_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2261406699408689122736795683\", ldavis_el2261406699408689122736795683_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic = []\n",
        "topic.append(optimal_model.show_topics(formatted=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAAzRibhria1",
        "outputId": "bf382aab-4199-41d6-a1b2-d013849834e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "topic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmn9gVKor14g",
        "outputId": "eaef9a0e-7f35-4db4-9119-719b530d8e67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[(12,\n",
              "   '0.060*\"session\" + 0.028*\"therapy\" + 0.017*\"issue\" + 0.017*\"problem\" + 0.015*\"work\" + 0.013*\"thing\" + 0.012*\"counselor\" + 0.012*\"appointment\" + 0.012*\"day\" + 0.011*\"doctor\"'),\n",
              "  (1,\n",
              "   '0.019*\"helpful\" + 0.019*\"person\" + 0.019*\"patient\" + 0.019*\"session\" + 0.010*\"robin\" + 0.010*\"foxman\" + 0.010*\"hope\" + 0.010*\"suggestion\" + 0.010*\"real\" + 0.010*\"passion\"'),\n",
              "  (10,\n",
              "   '0.032*\"counselor\" + 0.023*\"year\" + 0.021*\"problem\" + 0.019*\"time\" + 0.017*\"service\" + 0.016*\"help\" + 0.014*\"counseling\" + 0.014*\"good\" + 0.012*\"able\" + 0.012*\"questionnaire\"'),\n",
              "  (9,\n",
              "   '0.021*\"time\" + 0.020*\"therapist\" + 0.018*\"mental\" + 0.016*\"issue\" + 0.016*\"bad\" + 0.016*\"therapy\" + 0.015*\"session\" + 0.013*\"health\" + 0.012*\"good\" + 0.012*\"phone\"'),\n",
              "  (5,\n",
              "   '0.029*\"reason\" + 0.025*\"counselor\" + 0.022*\"first\" + 0.018*\"session\" + 0.015*\"second\" + 0.015*\"happy\" + 0.014*\"health\" + 0.014*\"mental\" + 0.013*\"thought\" + 0.013*\"counseling\"'),\n",
              "  (0,\n",
              "   '0.032*\"time\" + 0.018*\"therapist\" + 0.017*\"work\" + 0.015*\"month\" + 0.013*\"issue\" + 0.011*\"talk\" + 0.011*\"session\" + 0.011*\"negative\" + 0.011*\"message\" + 0.011*\"therapy\"'),\n",
              "  (3,\n",
              "   '0.035*\"month\" + 0.035*\"last\" + 0.012*\"ptsd\" + 0.012*\"pleasant\" + 0.012*\"problem\" + 0.012*\"timely\" + 0.012*\"mental\" + 0.012*\"personal\" + 0.012*\"party\" + 0.012*\"complicated\"'),\n",
              "  (8,\n",
              "   '0.015*\"session\" + 0.014*\"therapist\" + 0.014*\"work\" + 0.012*\"constant\" + 0.012*\"survey\" + 0.012*\"responsive\" + 0.012*\"client\" + 0.012*\"time\" + 0.012*\"worried\" + 0.012*\"crap\"'),\n",
              "  (4,\n",
              "   '0.042*\"life\" + 0.023*\"counselor\" + 0.022*\"therapist\" + 0.016*\"well\" + 0.013*\"client\" + 0.012*\"friend\" + 0.011*\"relationship\" + 0.011*\"step\" + 0.011*\"appointment\" + 0.011*\"experience\"'),\n",
              "  (11,\n",
              "   '0.024*\"good\" + 0.021*\"week\" + 0.020*\"anxiety\" + 0.020*\"briley\" + 0.014*\"time\" + 0.013*\"mental\" + 0.012*\"therapist\" + 0.010*\"uncomfortable\" + 0.010*\"conversation\" + 0.010*\"thing\"')]]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(topic)\n",
        "df = df.transpose()\n",
        "df.to_csv('get.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln5cnyFqr7re",
        "outputId": "f720926d-51fa-4b88-dcd8-e34ec9179644"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "id": "wdC3qqfKsDJ6",
        "outputId": "49588744-2e63-44d9-a560-b86b69b06275"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   0\n",
              "0  (12, 0.060*\"session\" + 0.028*\"therapy\" + 0.017...\n",
              "1  (0, 0.032*\"time\" + 0.018*\"therapist\" + 0.017*\"...\n",
              "2  (8, 0.015*\"session\" + 0.014*\"therapist\" + 0.01...\n",
              "3  (2, 0.024*\"therapist\" + 0.023*\"help\" + 0.023*\"...\n",
              "4  (1, 0.019*\"helpful\" + 0.019*\"person\" + 0.019*\"...\n",
              "5  (9, 0.021*\"time\" + 0.020*\"therapist\" + 0.018*\"...\n",
              "6  (10, 0.032*\"counselor\" + 0.023*\"year\" + 0.021*...\n",
              "7  (11, 0.024*\"good\" + 0.021*\"week\" + 0.020*\"anxi...\n",
              "8  (4, 0.042*\"life\" + 0.023*\"counselor\" + 0.022*\"...\n",
              "9  (6, 0.036*\"time\" + 0.024*\"good\" + 0.018*\"couns..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-72e3ea0a-62a1-47d4-a362-ffdd9012ecca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(12, 0.060*\"session\" + 0.028*\"therapy\" + 0.017...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(0, 0.032*\"time\" + 0.018*\"therapist\" + 0.017*\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(8, 0.015*\"session\" + 0.014*\"therapist\" + 0.01...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(2, 0.024*\"therapist\" + 0.023*\"help\" + 0.023*\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(1, 0.019*\"helpful\" + 0.019*\"person\" + 0.019*\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(9, 0.021*\"time\" + 0.020*\"therapist\" + 0.018*\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(10, 0.032*\"counselor\" + 0.023*\"year\" + 0.021*...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(11, 0.024*\"good\" + 0.021*\"week\" + 0.020*\"anxi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(4, 0.042*\"life\" + 0.023*\"counselor\" + 0.022*\"...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(6, 0.036*\"time\" + 0.024*\"good\" + 0.018*\"couns...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-72e3ea0a-62a1-47d4-a362-ffdd9012ecca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-72e3ea0a-62a1-47d4-a362-ffdd9012ecca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-72e3ea0a-62a1-47d4-a362-ffdd9012ecca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M6W5pPlysOqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}